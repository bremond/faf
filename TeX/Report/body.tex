\newcommand{\tb}[1]{\textcolor{blue}{#1}}
\section*{Notation}

The following notation is used throughout the paper. The 2-norm for a function $f$ is denoted  by $\|f\|$ and for a vector $x\in\RR^n$ by $\|x\|$. 
The set $ K^\star $ is the dual convex cone to a convex cone $K$ defined by
\begin{equation}
  \label{eq:dual-cone}
  K^\star = \{u \in \RR^3 \mid  r^\top u \geq 0, \quad \text{for all } r \in K   \}.
\end{equation}
\section{Introduction}

\citet{Panagiotopoulos_IA1975} ?

More than thirty years after the pioneering work of \cite{Necas.ea1980}, \cite{Haslinger1983,Haslinger1984},\cite{Katona_IJNAMG1983}, \cite{Chaudhary.Bathe_CS1986}, \cite{Jean.Moreau1987}, \cite{Mitsopoulou.Doudoumis1988} on numerically solving mechanical problems with contact and friction, there is still an active research activities on this subject in the computational mechanics and applied mathematics communities.  This can be explain by the fact that  mechanical systems with unilateral contact and Coulomb friction are difficult to numerically solve and the mathematical results of convergence of the numerical algorithms are rare and most of these require strong assumptions. In this paper, we want to give some insights of the advantages and weaknesses of standard solvers found in the literature by comparing them on the large sets of examples coming from a wide range of mechanical systems.

To fix ideas, we want to discuss possible numerical solution procedures for the following three--dimensional discrete frictional contact problem and some of its variants.  Let $n_c\in \NN$ be the number of contact points and $n\in\NN$ the number of degree of freedom of a discrete mechanical system.  \tb{For each contact $\alpha$, the unknown local variables  $u^\alpha\in\RR^3$ (relative velocity or gap at the contact point) and $r^\alpha\in\RR^3$ (reaction or impulse) are decomposed  in a contact local basis $({\sf N}^\alpha,{\sf T_1}^\alpha,{\sf T_2}^\alpha)$ such that $u^\alpha = u^\alpha_{\n} {\sf N}^\alpha +   u^{\alpha}_{\tone}{\sf T_1}^\alpha + u^{\alpha}_{\ttwo}{\sf T_2}^\alpha , u^\alpha_{\n} \in \RR, u^\alpha_{\t} = [u^{\alpha}_{\tone},u^{\alpha}_{\ttwo}]^\top \in \RR^2$ and  $r^\alpha = r^\alpha_{\n} {\sf N}^\alpha +   r^{\alpha}_{\tone}{\sf T_1}^\alpha + r^{\alpha}_{\ttwo}{\sf T_2}^\alpha  , r^\alpha_{\n} \in \RR, r^\alpha_{\t}=[r^{\alpha}_{\tone},r^{\alpha}_{\ttwo}]^\top \in \RR^2$ (see Figure~\ref{fig:local-frame}).}

 Given a symmetric positive (semi-)definite matrix ${M} \in \RR^{n \times n}$, a vector $ {f} \in \RR^n$, a matrix  ${H} \in \RR^{n \times m}$ with $m= 3n_c$, a vector $w \in \RR^{m}$ and a vector of coefficients of friction $\mu \in \RR^{n_c}$, find two vectors $ {v} \in \RR^n$ and $r\in \RR^m$ such that
\begin{equation}\label{eq:soccp1-intro}
  \begin{array}{rcl}
    M v = {H} {r} + {f}, &
    u = H^\top v + w,  &
    \hat u = u + g(u) ,\\[1mm]
    &    K^\star \ni {\hat u} \perp r \in K,&
  \end{array}
\end{equation}
where the set $K$ is the cartesian product of Coulomb's friction cone at each contact, that is
\begin{equation}
  \label{eq:CC}
  K = \prod_{\alpha=1\ldots n_c} K^{\alpha}  = \prod_{\alpha=1\ldots n_c} \{r^\alpha, \|r^\alpha_\t \| \leq \mu^\alpha |r^\alpha_\n| \}
\end{equation}
and $K^\star$ is dual. The function $g(u)$ is a nonsmooth function defined as
\begin{equation}
g(u) = [[\mu^\alpha  \|u^\alpha_\t\| {\sf N}^\alpha]^\top, \alpha = 1\ldots n_c]^\top\label{eq:gg}. 
\end{equation}\tb{The variable $u$ and $\hat u$  do not appear as unknowns since they can be directly obtained from $v$.}
\tb{The vector is}
\begin{figure}
  \centering
  \begin{tikzpicture}[ scale=4,
      axis/.style={ ->, >=stealth'},
      normal/.style={ thick, ->, >=stealth'},
      important line/.style={very thick},
      dashed line/.style={dashed, thin},
      every node/.style={color=black},
      soldot/.style={only marks,mark=*},
      holdot/.style={fill=white,only marks,mark=*}
      ]
      % body
      \node (BodyA) at (1,-1) {Body A};
      \fill[gray!20] (1,0) arc (0:-90:1);
      \fill[gray!20] (1,0) arc (90:180:1);
      \draw (1,0) arc (90:180:1);

      \node (BodyB) at (-1,1) {Body B};
      \draw (0,1) arc (0:-90:1);
      \fill[gray!20] (0,1) arc (90:180:1);
      \fill[gray!20] (0,1) arc (0:-90:1);

      % local frame
      \def\nlength{0.35};
      \coordinate (CA)  at  ({1.0-sqrt(2)/2.0},{-1.0+sqrt(2)/2.0});
      \node[] at  (CA) [below] {$\sf C_A$};
      \draw[holdot]  (CA) circle(0.05em);
      \draw[normal] (CA) -- ($(CA)+({-\nlength*sqrt(2)/2.0},{+\nlength*sqrt(2)/2.0 })$) node [right] {$\,\sf N$};
      \draw[normal] (CA) -- ($(CA)+({-\nlength*sqrt(2)/2.0},{-\nlength*sqrt(2)/2.0 })$) node [above] {$\sf T_1\quad$};
      \draw[dashed line] (BodyA) -- (BodyB);
      \draw[holdot] ($(CA)+({\nlength*sqrt(3)/2.0},{0.0})$) circle(0.2em);
      \node at ($(CA)+({\nlength*sqrt(3)/2.0},{0.0})$) [right]{$\sf T_2$};
      \draw[soldot] ($(CA)+({\nlength*sqrt(3)/2.0},{0.0})$) circle(0.02em);

      \coordinate (CB)  at  ({-1.0+sqrt(2)/2.0},{1.0-sqrt(2)/2.0});
      \node at  (CB) [above] {$\sf C_B$};
      \draw[holdot]  (CB) circle(0.05em);

      \draw[axis] (CA) -- (CB) node[midway, below left ] {$\sf g_\n$} ;
      
      % \draw[axis] (0,-0.4) -- (0,0.4) node(yline)[right] {$\sgn(x)$};
      % % lines
      % \draw[important line] (-0.4,-0.3) -- (0.   ,-.3);
      % \draw[important line] (0.0,0.3) --(.4,.3)  ;
      % \coordinate (O) at (0.0, 0.05);
      % \draw[fill] (O) circle (0.03em);
      % \draw (0.0,0.05) node[right]{$a$};
      % \draw (0.0,0.3) node[left]{$1$};
      % \draw (0.0,-0.3) node[right]{$-1$};
      % \draw[holdot] (0.0,0.3) circle (0.03em);
      % \draw[holdot] (0.0,-.3) circle (0.03em);
    \end{tikzpicture}
\caption{Contact kinematic}
\label{fig:local-frame}
\end{figure}

We clearly choose to simplify a lot the general problems of formulating the contact problems with friction by avoiding to include too much side effects that are themselves interesting but render the study to difficult to carry out in a single article. We choose finite dimensional systems where the time dependence does not appear explicitely. For instance, we consider systems that are discretized in space and time if the original system is not a finite dimensional system and if a dynamic or a quasi--static evolution is considered. In the same way, we consider a linear setting in a first attempt and we assume that  nonlinear mechanical bulk behaviors that can be treated at an upper level with a Newton linearization procedure. Even under these assumptions, we believe that there are a strong interest to work on the problem since it appears to be relativey generic in a large number of simulations of systems with contact and friction. This problem is indeed at the heart of the simulation of mechanical systems with 3D Coulomb's friction and unilateral constraints: it might be the result of the time--discretization by event--capturing time--stepping methods or event--detecting (event--driven) techniques of dynamical systems with friction or the result of a space--discretization (by FEM for instance) of the quasi-static problems of frictional contact mechanics. For a description of the derivation of such problems in various practical situations we refer to~\cite{Acary.Brogliato2008,Acary.Cadoux2013}.{\tt XXX discuss the remark Olivier about the motion of this paragraph. }

From the mathematical programming point of view, the problem appears to be a Second Order Cone Complementarity Problem (SOCCP)~\cite{Facchinei.Pang2003} which can be generically defined as
\begin{equation}
  \begin{cases}
    y =f(x) \\
    K^\star \ni x \perp y \in K
  \end{cases}
\end{equation}
where $K$ is a second order cone. If the nonlinear part of the problem (\ref{eq:soccp1-intro}) is neglected ($g(u)=0$), the problem is an associated friction problem with dilatation, and by the way, is a gentle Second Order Cone Linear Complementarity Problem (SOCLCP) with a positive definite matrix $H^\top M^{-1} H$ (possibly semi--definite).\tb{The assumption of associated frictional law, i.e, a friction law where the local sliding velocity is normal the friction cone differs dramatically from the standard Coulomb friction since it generates a non--vanishing normal velocity when we slide. In other terms, the sliding motion implies the separation of the bodies.}
When the non-associated character of the friction is taken into account through $g(u)$, the problem is non monotone and nonsmooth, and then very hard to solve efficiently. For a given numerical algorithm, it is not so difficult to design mechanical example to run the algorithm into troubles. The mathematical results of convergence of the numerical algorithms are rare and most of these required strong assumptions such that  the amount of friction, or full rank assumptions of matrices or operators or the dimension of the space in which the problem is formulated. Among these results, we can cite the Czech school where the coefficient of friction is assumed to be bounded and small. This assumption allows us to use fixed point methods on the convex sub--problems of Tresca friction \tb{(friction threshold that does depend on the normal reaction and then transform the cone into a semi-cylinder)}. We can also cite the result that are obtained in~\cite{Pang.Trinkle1996,Stewart.Trinkle1996,Anitescu.Potra97} where the friction cone is polyhedral (in 2D or by a faceting process). In that case, if $w=0$ or $w \in \mathrm{im}(H^\top)$, Lemke's algorithm is able to solve the problem. The question of existence of solutions has been treated in~\cite{Klarbring.Pang1998,Acary.ea_ZAMM2011} under similar assumptions but with different techniques. The question of uniqueness remains a difficult problems in the general case.


In this article,  after stating the problem with more details in Section~\ref{sec:description}, we recall the existence result of~\cite{Acary.ea_ZAMM2011} for the problem in~(\ref{eq:soccp1-intro}) in Section \ref{sec:existence}. In this framework, we briefly present in Section~\ref{sec:formulation} a list of alternative formulations of the problem that enable the design of numerical solution procedures. Right after these formulations, we list some of the most standard algorithms dedicated to one of the previous formulation in Sections~\ref{sec:numericalmethods,vi},~\ref{sec:newtonmethods},~\ref{Sec:SplittingTechniquesAndProx}, \ref{Sec:InteriorPoint} and \ref{Sec:OptimisationBasedMethods}. These algorithms that have been previously developed for solving the SOCCP~(\ref{eq:soccp1-intro}) are mainly based  variational inequality (Section~\ref{sec:numericalmethods,vi} and~\ref{Sec:SplittingTechniquesAndProx}) and nonsmooth equations (Section~\ref{sec:newtonmethods}) or  optimization--based (Section~\ref{Sec:OptimisationBasedMethods}) reformulations.  

Since it is difficult to be exhaustive on the approaches developed in the literature to solve frictional contact problems, we decided to leave out the scope of the paper the following approaches:
\begin{itemize}
\item the approaches that alter the fundamental assumptions of the 3D Coulomb friction model by faceting the cone as in the pioneering work of \cite{Klarbring1986} and followed by~\cite{AlFahed.Stavroulakis.ea1991,Pang.Trinkle1996,Stewart.Trinkle1996,Anitescu.Potra97,Haslinger.ea_JCAM2004}, or by convexifying the Coulomb law (associated friction law with normal dilatency)~\cite{Heyn.ea_IJNME2013,Tasora.Anistescu_Meccanica2013,Tasora.Anistescu_CMAME2011,Anistescu.Tasora_COA2010,Tasora.Anistescu_CMAME2009} or finally by regularizing the friction law~\cite{Kikuchi.Oden_SIAM1988}.
\item Approaches that not give satisfactory results
\item Approaches that we have not yet implemented. Interior point. SOCCP Solver ??
\end{itemize}

Other comparisons articles have already been published in the literature. Cite and comment

\begin{list}{}{}
\item \cite{Raous.ea1988,Chabrand.ea_MCM1998}
\item \cite{Christensen.Klarbring.ea1998}
\item \cite{Mijar.Arora_SMO2000,Mijar.Arora_ACME2000,Mirar.Arora_SMO2004-I,Mirar.Arora_SMO2004-II}
\end{list}


The comparison are performed on a large set of examples using performance profiles. The main conclusion that are drawn from Section~\ref{sec:numericalcomparisons} are as follows.
On one hand, we will show that algorithms based on Newton methods for nonsmooth equations solve quickly the problem when they succeed, but suffer from robustness issues mainly if the matrix $H$ has not full rank. On the other hand, the
iterative methods dedicated to solving variational inequalities are quite robust but with an extremely slow rate of convergence. To sum up, as far as we know there is no option that combines time efficiency and robustness. To try to answer to this question, we develop an open collection of discrete frictional contact problems called FCLIB~\url{http://fclib.gforge.inria.fr} in order to offer a large library of problems to compare algorithms on a fair basis.  In this work, this collection is solved with the software {\sc Siconos} and its component {\sc Siconos/Numerics}~\url{http://siconos.gforge.inria.fr}\citep{Acary.Bremond.Huber.Perignon2015}.


\clearpage
\section{Description of the 3D frictional contact problems}
\label{sec:description}
\subsection{Signorini's condition and Coulomb's friction.}

Let us consider first the contact between two  bodies $A \subset  \R^3$ and $B \subset \R^3$ with sufficiently smooth boundaries. (see Figure \ref{fig:local-frame}). Let us consider a point $C_{A} \in \partial A$ called a master point to contact.  The choice of this master point $C_A$ to write the contact condition is crucial in  practice and amounts to consistently discretizing  the contact surface. The vector  ${\sf N}$ defines an outward unit normal vector to $A$ at the point $C_A$. The normal vector is completed with two tangent vectors $\sf T_1, T_2$ such that $(C_A, \sf N, T_1, T_2)$ is an orthornormal frame called the \textit{local frame at contact}. The slave contact point $C_B \in \partial B$ is defined as the projection of the point $C_A$ on $\partial B$ in the direction given by $\sf N$. Note that we assume that such a point exists. The gap function is defined as the signed distance between $C_A$ and $C_B$
\begin{equation}
  \label{eq:gap}
  g_{\n} = (C_B-C_A)^\top  \sf N.
\end{equation}


To fix ideas, if we consider two strictly convex bodies, which are non penetrating, {\it i.e.}  $A \cap B = \emptyset$, the master and slave contact points can be chosen as the proximal points of each bodies and the normal vector  ${\sf N}$ can be written as
\begin{equation}
  \label{eq:normal}
  {\sf N} = \Frac{C_B-C_A}{\|C_B-C_A\|}.
\end{equation}



The contact force exerted by $A$ on $B$ is denoted by $r \in \RR^3$ and is decomposed in the local frame as
\begin{equation}
  \label{eq:reaction}
  r = r_{\n} {\sf N} +   r_{\tone}{\sf T_1} + r_{\ttwo}{\sf T_2}  ,\quad \text{ with  } r_{\n} \in \RR, r_{\t}=[r_{\tone},r_{\ttwo}]^\top \in \RR^2
\end{equation}

The \textit{Signorini condition} states that
\begin{equation}
  \label{eq:signo}
  0 \leq g_{\n} \perp r_\n \geq 0.
\end{equation}
 and models the unilateral contact. The condition~(\ref{eq:signo}) written at the position level, can also be defined at the velocity level. To that aim, the relative velocity $u \in \RR^3$ of the point $C_{B}$ with respect to $C_{A}$ is also decomposed in the local frame
\begin{equation}
  \label{eq:velocity}
  u =  u_\n {\sf N} +  u_{\tone}{\sf T_1} + u_{\ttwo}{\sf T_2}  \quad \text{ with } u_\n \in \RR \text{ and } u_\t=[u_{\tone},u_{\ttwo}]^\top  \in \RR^2.
\end{equation}
The velocity level formulation of the Signorini condition is written 
\begin{equation}
  \label{eq:signo-velocity}
  \left\{\begin{array}{ll}
  0 \leq u_{\n} \perp r_\n \geq 0  &\text{ if } g_{\n} \leq 0 \\
  r_{\n} =0 &\text{ otherwise}.
\end{array}\right.
\end{equation}
The Moreau's viability Lemma~\cite{Moreau1988} ensures that~(\ref{eq:signo-velocity}) implies (\ref{eq:signo}) if $g_{\n}\geq 0$ holds in the initial configuration.

Coulomb's friction  models the frictional behavior of the contact force law in the tangent plane \tb{ spanned by $(T_1,T_2)$}. Let us define the Coulomb friction  cone $K$ which is chosen as the isotropic second order cone (Lorentz or ice--cream cone)
\begin{equation}
  \label{eq:CoulombCone}
  K = \{r \in \RR^3 \mid \|r_\t\| \leq \mu r_n\},
\end{equation}
where $\mu$ is the coefficient of friction. The Coulomb friction  states for the sticking case that 
\begin{equation}
  \label{eq:Coulom-stick}
  u_{\t} =0,\quad r \in K
\end{equation}
and for the sliding case that
\begin{equation}
  \label{eq:Coulom-slide}
  u_{\t}  \neq 0,\quad r \in \partial K, \exists\, \alpha > 0, r_\t = -\alpha u_\t.
\end{equation}
\tb{With the Coulomb friction model, there are two relations between $u_\t$ and $r_\t$. The distinction is based on the value of the relative velocity $u_\t$ between the two bodies. If $u_\t=0$ (sticking case), we have $r_\t \leq \mu r_n$. On the other hand, we get the sliding case.} 

\paragraph{Disjunctive formulation of the Signorini-Coulomb model}

If we consider the velocity-level Signorini condition~(\ref{eq:signo-velocity}) together with the Coulomb friction~(\ref{eq:Coulom-stick})--(\ref{eq:Coulom-slide}) which is naturally expressed in terms of velocity, we obtain a disjunctive formulation of the frictional contact behavior as
\begin{equation}
  \label{eq:contact-disjunctive}
  \left\{\begin{array}{llr}
      r = 0  &\text{ if } g_{\n} > 0  & \text{(no contact)}\\
      r = 0,  u_\n \geq 0   &\text{ if } g_{\n} \leq 0 & \text{(take--off)} \\
      r \in K, u =0 &\text{ if } g_{\n} \leq 0 & \text{(sticking)}  \\
      r \in \partial K,u _\n=0,  \exists\,\alpha > 0, u_\t = -\alpha r_\t &\text{ if } g_{\n} \leq 0 & \text{(sliding)}  \\
\end{array}\right.
\end{equation}
In the computational practice, the disjunctive formulation is not suitable for  solving the Coulomb problem as it suggests the use of enumerative solvers. In the sequel, alternative formulations of the Signorini-Coulomb model prone to numerical applications will be delineated.

\paragraph{Inclusion into normal cones} The Signorini condition~(\ref{eq:signo}) in their complementarity forms can be equivalently written  as an inclusion into a normal cone to $\RR_+$
\begin{equation}
  \label{eq:signo-inclusion}
  - g_\n \in N_{\RR_+}(r_\n),
\end{equation}
and respectively for~(\ref{eq:signo-velocity})
\begin{equation}
  \label{eq:signo-inclusion-velo}
  - u_\n \in N_{\RR_+}(r_\n),
\end{equation}
if $g_{\n} \leq 0$ and $r_\n =0 $ otherwise. An inclusion form of the Coulomb friction can be also proposed introducing the Coulomb disk $D(\mu r_n)$
\begin{equation}
  \label{eq:diskR}
  D(\mu r_\n) = \{r_\t \in \RR^2\mid \|r_T\| \leq \mu r_\n   \}.
\end{equation}
For the Coulomb friction, we get
\begin{equation}
  \label{eq:Coulomb-inclusion}
  - u_{\t} \in N_{D(\mu r_\n)}.
\end{equation}
Since $D(\mu r_\n)$ is not a cone, (\ref{eq:Coulomb-inclusion}) is not a complementarity problem.  The formulation~(\ref{eq:Coulomb-inclusion}) is often related to Moreau's maximum dissipation principle of the frictional behavior,
\begin{equation}
  \label{eq:moreau-maxprinciple}
  r_\t = \mbox{argmax}_{\|z\| \leq \mu r_n}  z^\top u_\t.
\end{equation}
This means that the couple $(r_\t,u_\t)$ maximizes the energy lost through dissipation.


\paragraph{SOCCP formulation of the Signorini-Coulomb model}

In \cite{Acary.Brogliato2008,Acary.ea_ZAMM2011}, another formulation is proposed inspired by the so-called bipotential \cite{DeSaxce92,DeSaxce.Feng90,DeSaxce.Feng_MCM1998}. Operating a change of variable, we introduce the modified relative velocity $\hat u \in \RR^3$ defined by
\begin{equation}
  \label{eq:modified-velocity}
  \hat u = u +\mu \|u_\t\| \sf N.
\end{equation}
The entire contact model (\ref{eq:contact-disjunctive}) can be put into a Second-Order Cone Complementarity Problem (SOCCP) as
\begin{equation}
  \label{eq:contact-SOCCP}
 K^\star \ni \hat u \perp r \in K
\end{equation}
 if $ g_\n \leq 0 $ and $r=0$ otherwise. 
\begin{figure}\centering
  \resizebox{!}{0.5\textheight}{\input{../figure/cone1-b.pdf_t}}
  \caption{Coulomb's friction law in the sliding case.}
\label{fig:CoulombLawSliding}
\end{figure}

% \begin{tikzpicture}
%   % \tkzCone{3}{0.5}{5};\hspace{4cm}
%   % \tkzCone{5}{1.0}{5};\hspace{4cm}
%    \tkzCone{3}{2.0}{8};\hspace{4cm}
%   %\tkzCone{5}{0.1}{5};
% \end{tikzpicture}



\subsection{Frictional contact discrete problems}

In this section, we formulate two basic discrete frictional contact problems considering a finite number $n$ of degrees of freedom  together with a discrete linear dynamics.\tb{ The first problem is directly related to (\ref{eq:soccp1-intro}) and keep the unknown triplet $(v,u,r)$. The second problem will assume that the matrix $M$ is invertible. In that later case, we case eliminate the variable $v$ and reduce the unknown to the couple ($(u,r)$).}

 We assume that a finite set of $n_c$ contact points and their associated local frames has been defined. In general, this task is not straightforward and amounts to correctly discretizing  the contact surfaces. For more details, we refer to \cite{Wriggers2006,Laursen2003}.

For each contact $\alpha \in \{1,\ldots n_c\}$, the  local velocity  is denoted by $u \in \RR^3$, the normal velocity by $u_\n^{\alpha}\in \RR$ and the tangential velocity by $u_\t^\alpha\in\RR^2$. One obviously 
gets
\begin{equation}
  \label{eq:contactvelocity}
  u^\alpha =\left[
  \begin{array}{c}
    u^\alpha_{\n} \\
    u^\alpha_{\t}   
  \end{array}\right].
\end{equation}
The vector $u, u_\n, u_\t$ respectively collects all the local velocity
$  u = [[u^\alpha]^\top, \alpha = 1\ldots n_c]^\top$,
all the normal velocity 
$
  u_\n = [ u^\alpha_{\n}, \alpha = 1\ldots n_c]^\top$,
and all the  tangential velocity
$
  u_\t = [ [u^\alpha_{\t}]^\top, \alpha = 1\ldots n_c]^\top$.
For a contact $\alpha $, the modified local velocity, denoted by $\hat u^\alpha $, is defined by
\begin{equation}
  \label{eq:modified}
  \hat u^\alpha = u^\alpha + g^\alpha(u)
\end{equation}
where
\begin{equation}
  \label{eq:modified-bis}
  g^\alpha(u) =  \mu^\alpha  \|u^\alpha_\t\| {\sf N}^\alpha.
\end{equation}
The vectors $\hat u$ and $g(u)$ collect all the modified local velocity at each contact $\hat u = [[\hat u^\alpha]^\top, \alpha = 1\ldots n_c]^\top$ and the function $g(u) = [[\mu^\alpha  \|u^\alpha_\t\| {\sf N}^\alpha]^\top, \alpha = 1\ldots n_c]^\top$.

% Let us introduce finally the following notation to express the function $g(u)$ in a convenient manner. We denoted by $s^\alpha = \|u^\alpha_\t\|$ the norm of the sliding velocity for the contact $\alpha$. The vector $s$ collects all the sliding velocity at each contact $s = [ s^\alpha, \alpha = 1\ldots n_c]^\top$. The matrix $ N \in \RR^{3n_c\times n_c}$ is composed of the vector $ mu^\alpha N^\alpha$ on its diagonal formally $N = \mbox{diag}(\mu^\alpha N^\alpha$. The function $g()$ can be therefore expressed as $g(u) = N s$.

For each contact $\alpha$, the reaction vector $r^\alpha\in \RR^3$ is also decomposed in its normal part $r_\n^{\alpha}\in \RR$ and the tangential part $r_\t^\alpha\in\RR^2$ as
\begin{equation}
  \label{eq:contactreaction}
  r^\alpha = \left[
  \begin{array}{c}
    r^\alpha_{\n} \\
    r^\alpha_{\t}   
  \end{array}\right].
\end{equation}
The Coulomb friction cone for a  contact $\alpha$ is defined by $K^{\alpha}  = \{r^\alpha, \|r^\alpha_\t \| \leq \mu^\alpha |r^\alpha_\n| \}$ and the set $K^{\alpha,\star}$ is its dual. 
The set $K$ is the cartesian product of Coulomb's friction cone at each contact, that 
\begin{equation}
  \label{eq:CC}
  K = \prod_{\alpha=1\ldots n_c} K^{\alpha} 
\end{equation}
and $K^\star$ is dual.

Let us now introduce two basic frictional contact problems defined in terms of complementarity overs cones.
\begin{problem}[Discrete frictional contact problem]\label{prob:I}
  Given
  \begin{itemize}
    \item a symmetric positive definite matrix ${M} \in \nbR^{n \times n}$,
    \item a vector $ {f} \in \nbR^n$,
    \item a matrix  ${H} \in \nbR^{n \times m}$,
    \item a vector $w \in \RR^{m}$,
    \item a vector of coefficients of friction $\mu \in \RR^{n_c}$,
  \end{itemize}
find two vectors $ {v} \in \nbR^n$ and $r\in \RR^m$, denoted by $\mathrm{FC/I}(M,H,f,w,\mu)$  such that
\begin{equation}\label{eq:soccp1}
  \begin{cases}
    M v = {H} {r} + {f} \\[2mm]
    u = H^\top v + w \\[2mm]
    \hat u = u + g(u) \\[2mm]
    K^\star \ni {\hat u} \perp r \in K
  \end{cases}
\end{equation}
with $g(u) = [[\mu^\alpha  \|u^\alpha_\t\| {\sf N}^\alpha]^\top, \alpha = 1\ldots n_c]^\top$. 
\qed
\end{problem}

\begin{problem}[Local discrete frictional contact problem]\label{prob:II}
  Given
  \begin{itemize}
    \item a symmetric positive semi--definite  matrix ${W} \in \nbR^{m \times m}$,
    \item a vector $ {q} \in \nbR^m$,
    \item a vector $\mu \in \RR^{n_c}$ of coefficients of friction, 
  \end{itemize}
find  a vector $r\in \RR^m$, denoted by $\mathrm{FC/II}(W,q,\mu)$  such that
\begin{equation}\label{eq:soccp2}
  \begin{cases}
    u =Wr +q \\[2mm]
    \hat u =u + g(u) \\[2mm]
    K^\star \ni {\hat u} \perp r \in K
  \end{cases}
\end{equation}
with $g(u) = [[\mu^\alpha  \|u^\alpha_\t\| {\sf N}^\alpha]^\top, \alpha = 1\ldots n_c]^\top$.
\qed
\end{problem}

%The  first two lines of (\ref{eq:soccp1}) may represent a linear time--discretized dynamics and $v$ have the role of the global or generalized velocity. 


%We will see in the next section how these systems can be  obtained and how they may also be an instance of a quasi-static problem
% Nonlinear versions of this problem can also be stated but they are out pf the scope of the paper. When the dynamics is nonlinear, an outer Newton linearization is performed leading to a linearized problem. 


Problem~\ref{prob:II} is also often referenced as the \textit{condensed} or \textit{reduced} problem. The two problems are closely related. Indeed, if we consider the inverse of the matrix $M$ we obtain an explicit equation for $v$ in Problem~\ref{prob:I}
\begin{equation}
  \label{eq:vv}
  v = M^{-1}\,(Hr +f).
\end{equation}
Substituting (\ref{eq:vv}) in the first line of~(\ref{eq:soccp1}), we get
\begin{equation}
  \label{eq:vv-1}
  u = H^\top M^{-1} H r + H^\top M^{-1} f +w.
\end{equation}
The matrix $W$, often called the \textit{Delassus matrix}, is easily identified as
\begin{equation}
  \label{eq:Delassus}
  W = H^\top M^{-1} H 
\end{equation}
and the vector $q$ as
\begin{equation}
  \label{eq:qq}
  q = H^\top M^{-1} f + w.
\end{equation}

\paragraph{Comments} The variable $\hat u$ does not explicitly appear as a variable of the problem since the mapping $u \mapsto u+g(u)$ is a one--to--one mapping.

\tb{Even if the matrix $M$ is invertible, the problem $\mathrm{FC/I}(M,H,f,w,\mu)$ and $\mathrm{FC/II}(W,q,\mu)$ are different from the point of view if their structure. The problem $\mathrm{FC/I}(M,H,f,w,\mu)$ enjoys good properties of sparsity in most of the applications. Either if $M$ comes from multi--body rigid systems or finite--element applications, it is sparse. It is also the same for $H$ since a contact relation involves at best two bodies. When we compute $W$, this sparsity may be lost for instance for systems that comes from finite--element applications, but the system is smaller in terms of number of unknowns. In~$\mathrm{FC/II}(W,q,\mu)$, the structure of $q$ has to be remarked from~(\ref{eq:qq}). Again, if $w=0$ or $w \in \mathrm{im}(H^\top)$, $q$ belongs to the range of $H^\top$ and we will see that it has some consequence on the existence of solutions in the sequel.}

\tb{}


\subsection{Existence of solutions}
\label{sec:existence}

The question of the existence of solution for problem~\ref{prob:I} and~\ref{prob:II} have been studied in~\cite{Klarbring.Pang1998} and~\cite{Acary.ea_ZAMM2011} with different analysis techniques. The key assumption for existence of solutions is both papers is as follows
\begin{equation}\label{ass}
   \exists v\in \RR^m \,:\: H^\top v + w \in \mathrm{int}\, K^\star,
\end{equation}
or equivalently
\begin{equation}\label{asseq}
  w\in\mathrm{im}\, H + \mathrm{int}\, K^\star.
\end{equation}
Under the assumption, the problems~\ref{prob:I} and~\ref{prob:II} have a solution. The question to provide a solution procedure to compute has therefore a sense. In the sequel, we will compare numerical methods only when this assumption is satisfied.

This assumption is easy verified in a large number of applications. For applications in nonsmooth dynamics where the unknown $v$ is a relative contact velocity, the term $w$ vanishes if we have only scleronomic constraints. For $w \in \mathrm{im}(H^\top)$ (and especially $w=0$), the assumption is trivially satisfied. Other practical situations are also detailed in~\cite{Acary.Cadoux2013}. \tb{As it is explained in~\cite{Acary.Cadoux2013}, the term $w$ has several possible sources. If the constraints are written at the velocity level, one is given in dynamics by the impact law and in that case, we can show that of the Newton impact law it holds that $w \in \mathrm{im}(H^\top)$.   For other impact law, this is not so clear. Another source for $w$ is given by constraints that depends explicitly on time. In that case, we can have $w \not\in \mathrm{im}(H^\top)$ and non existence of solutions. If the constraints are written at the position level, $w$ can be given by initial of terms that comes velocity discretization. In that cases, the existence is not clear.}

\tb{The assumption is also satisfied if $\mathrm{im}\, H = \RR^m$ or in other words if $H^\top$ has full row rank. Unfortunately, in large number of applications $H^\top$ is rank deficient. }
From the mechanical point of view, the rank deficiency of $H$ and the amount of friction seems to play a fundamental role in the question of the existence (and uniqueness) of solutions. In the numerical comparisons, we will attempt to get a deeper understanding on the role of these assumptions on the convergence of the algorithms. The rank deficiency  of $H$ is related to the number of constraints that are imposed to the system with respect to the number of degree of freedom in the system. It is closely related to the concept of hyperstaticity in overconstrained systems. In the most favorable cases, it yields  indeterminate Lagrange multipliers but also to unfeasible problems and then to the lost of solutions in the worth cases. The second assumption on the amount of friction is also well--know. The frictionless problem is  easy to solve if it is  feasible. It is clear that large friction coefficients prevent from sliding and the therefore increase the degree of hyperstaticity of the system. 



% \subsection{Origins of the discrete problem}

% \begin{ndrva}
%   Is it mandatory ?
% \end{ndrva}


% \subsubsection{Finite freedom mechanics}



% \subsubsection{Quasi-static frictional contact problem}

% \cite{Haslinger1983,Christensen.Klarbring.ea1998,Klarbring.Pang1999}

% \subsubsection{Dynamic frictional contact problem}

% \cite{Moreau1998,Moreau1994,Moreau1999}

\clearpage
%----------------------------------------------------------------------------------%
\section{Alternative formulations}
%----------------------------------------------------------------------------------%
\label{sec:formulation}
In this section, various equivalent formulations of Problems~\ref{prob:I} and~\ref{prob:II} are detailed. We aim at showing that such problems can be recast into several well-known problems in the mathematical programming and optimization community. These formulations will serve as a basis for  numerical solution procedures that we develop in further sections.

\subsection{Variational inequalities (VI) formulations}

Let us recall the definition a finite-dimensional VI denoted by $\mathrm{VI}(X,F)$: find $z\in X$ such that 
\begin{equation}
  \label{eq:vi}
  F^\top(z)(y-z) \geq 0, \text{ for all } y \in X,
\end{equation}
with $X$ a nonempty subset of $\RR^n$ and $F$ a mapping from $\RR^n$ into itself. We refer to~\cite{Harker.Pang1990,Facchinei.Pang2003} for the standard  theory of finite--dimensional variational inequalities. The easiest way to state equivalent VI formulations of Problems~\ref{prob:I} and~\ref{prob:II} is to use the following equivalences that
\begin{equation}
  \label{eq:SOCCP-1}
  K^\star \ni {\hat u} \perp r \in K \Longleftrightarrow
  - {\hat u} \in N_K(r)  \Longleftrightarrow \hat u^\top (s -r) \geq 0, \text{ for all } s \in K.
\end{equation}
For Problem~\ref{prob:I}, let us start by rewriting the problem~(\ref{eq:soccp1}) as a normal cone inclusion
\begin{equation}
  \label{eq:soccp1-bis}
  \left\{\begin{array}{l}
    M v-H r-f=0, \\[2mm]
   -(H^\top v + w + g(H^\top v + w)) \in N_K(r).
 \end{array}\right.
\end{equation}
The problem (\ref{eq:soccp1-bis}) is written as an inclusion into the normal cone to $\bar K = \RR^n  \times K\subset \RR^{m+n}$ as
\begin{equation}
  \label{eq:soccp1-ter}
  - \left[\begin{array}{l}
    M v-H r-f \\
    H^\top v+w  + g(H^\top v +w)
 \end{array}\right]    \in N_{\bar K}\left(
\left[\begin{array}{l}
  v \\r
\end{array}\right]
\right).
\end{equation}
Finally, the VI formulation of Problem~\ref{prob:I} is given by
\begin{equation}
  \label{eq:vi-I-bis}
  \left[\begin{array}{l}
    M v-H r-f \\
    H^\top v+w  + g(H^\top v +w)
  \end{array}\right] \left(
  \left[\begin{array}{l}
      p  \\ s
    \end{array}\right] - \left[\begin{array}{l}
      v  \\ r
    \end{array}\right]
\right) \geq 0,\quad \text{ for all } s \in K,  p \in \RR^n.
\end{equation}
Let us introduce a convenient notation for this formulation as $\mathrm{VI}(F_{\vione},X_{\vione})$ with
\begin{equation}
  \label{eq:vi-I}
  F_{\vione}(v,r) := \left[\begin{array}{l}
    M v-H r-f \\
    H^\top v+w  + g(H^\top v +w)
  \end{array}\right],\quad \text{ and } X_{\vione} = \bar K = \RR^n \times K\subset \RR^{n+m}.
\end{equation}
For Problem~\ref{prob:II}, the following equivalent formulation in VI is directly obtained from
\begin{equation}
  \label{eq:inclusion-1}
  -(W r + q + g(Wr+q))  \in N_K(r).
\end{equation}
 The resulting VI is denoted by $\mathrm{VI}(F_{\vitwo},X_{\vitwo})$ with
\begin{equation}
  \label{eq:vi-II}
  F_{\vitwo}(r) := W r +q + g(Wr+q)\text{ and } X_{\vitwo} = K.
\end{equation}

\paragraph{Solution properties.} 
Concerning the mathematical properties of the obtained VI formulations, it is difficult to provide a general result of existence and uniqueness of solutions. Nevertheless, in the case that the matrix $H$ has full rank and for small friction coefficients, a classical argument for the uniqueness of solution of VIs can be satisfied. Since $W$ is a positive definite matrix if $H$ has full rank, we have  $(x-y)^T W (x-y) \geq C_W \|x-y\|^2$ with  $C_W>0$ and then we obtain
\begin{equation}
  \label{eq:mono-II}
  \begin{array}{rcl}
    (F_{\vitwo}(x)-F_{\vitwo}(y))^T(x-y) &=& (x-y)^T W (x-y)  \\
    &  & \quad\quad + \sum _{\alpha =1}^{n_c} \mu^\alpha (x^\alpha_\n-y^\alpha_\n) [\|[Wx+q]^\alpha_\t \| - \|[Wy+q]^\alpha_\t \|] \\
    & \geq & C_W \|x-y\|^2  + \sum _{\alpha =1}^{n_c} \mu^\alpha (x^\alpha_\n-y^\alpha_\n) [\|[Wx+q]^\alpha_\t \| - \|[Wy+q]^\alpha_\t \|].
  \end{array}
\end{equation}
It is obvious that for small value of the coefficient of friction, the mapping $F_\vitwo$ is strictly monotone and this ensures that the VI has at most one solution~\citep[Theorem 2.3.3]{Facchinei.Pang2003}. The fact that $H$ is full rank also implies that the assumption (\ref{ass}) for the existence of solutions is trivially satisfied. We can therefore conclude that there exists a unique solution to the $\mathrm{VI}(F_{\vitwo},X_{\vitwo})$. It is also therefore easy to conclude to the existence of a unique solution for  $\mathrm{VI}(F_{\vione},X_{\vione})$.



\begin{ndrva}
  Use of homotopy (Haslinger ?)
\end{ndrva}

\subsection{Quasi-Variational Inequalities(QVI)}

Let $X$ be a multi-valued mapping  $\nbR^{n} \rightsquigarrow  \nbR^{n}$ and let  $F$ be a mapping from $\nbR^n$ into itself. The  quasi-variational inequality  problem, denoted by $\mathrm{QVI}(X,F)$ is to find a vector $z\in X(z)$ such that 
\begin{equation}
 \label{eq:qvi}
 F^{T}(z) (y-z) \ge 0, \, \forall y \in X(z).
\end{equation}
The QVI formulations of the frictional contact problems are obtained by considering the inclusions~(\ref{eq:signo-inclusion-velo}) and~(\ref{eq:Coulomb-inclusion}). We get 
\begin{equation}
  \label{eq:qvi-1}
  u^\top (s - r) \geq 0, \text{ for all } s \in C(\mu, r_\n),
\end{equation}
where $C(\mu, r_\n)$ is the Cartesian product of the semi--cylinders of radius $\mu^\alpha r_n^\alpha$ defined by
\begin{equation}
  \label{eq:cylinder}
  C(\mu, r_\n) = \prod_{\alpha =1}^{n_c} \{ s \in \RR^3 \mid  s_\n \geq 0, \|s_\t\| \leq \mu^\alpha r^\alpha_n     \}.
\end{equation}
Note that the QVI~(\ref{eq:qvi-1}) involves only $u$ and not $\hat u$; this is the main interest of formulating a QVI. The price to pay is the dependence on $r$ of the set $C(\mu,r_\n)$. The frictional contact problems~\ref{prob:I} and~\ref{prob:II}  can be expressed as a QVI by substituting the expression of $u$. For Problem~\ref{prob:II} we obtain
\begin{equation}
  \label{eq:qvi-IIbis}
   (Wr+q)^\top (s - r) \geq 0, \text{ for all } s \in C(\mu,r_\n).
\end{equation}
Since $W$ is assumed to be positive semi-definite  matrix, the affine mapping is monotone, thus we get an affine monotone $\mathrm{QVI}(F_{\qvitwo},X_{\qvitwo})$ with
\begin{equation}
  \label{eq:qvi-II}
  F_{\qvitwo}(r) :=  Wr+q \text{ and } X_{\qvitwo} = C(\mu,r_\n) .
\end{equation}


\subsection{Nonsmooth Equations}
\label{Sec:NonsmoothEquations}
In this section, we consider the reformulations of Problems~\ref{prob:I} and~\ref{prob:II} into various nonsmooth equations. More precisely for Problem~\ref{prob:I}, we search for an equation of the type
\begin{equation}
  \label{eq:ne-1}
  G(v,u,r) = 0
\end{equation}
where $G$ is nonsmooth (generally locally Lipschitz continuous) such that the zeroes $u,v,r$ of (\ref{eq:ne-1}) are the solutions of~(\ref{eq:soccp1}). With such a nonsmooth equations formulations, we will see further that several numerical methods can be used to solve it ranging from fixed point algorithms to Newton's method.

\paragraph{Natural and normal maps for the VI formulations}

A first way to obtain some formulations based on nonsmooth equations of the frictional contact problems is to use the normal and natural maps (see \cite{Facchinei.Pang2003} for details) which enables to restate a VI into a system of nonlinear and  nonsmooth functions.  Let us define the Euclidean projector $P_X$ onto a closed convex set  $X$. For a vector $x\in \RR^n$, the projected vector $\bar x  = P_X(x)$ is the unique solution of the convex quadratic programm
\begin{equation}
  \label{eq:opt-proj}
  \begin{cases}
    \min\, \Frac 1 2 (y-x)^T(y-x), \\[2mm]
    \begin{array}{ll}
    s.t. & y \in X .
  \end{array}
  \end{cases}
\end{equation}
 The natural map $F^\nat$ associated with the VI (\ref{eq:vi}) is defined by
\begin{equation}
  \label{eq:naturalmap}
  F^\nat(z) := z - P_{X}(z-F(z)),
\end{equation}
and  the normal map $F^\nor$ is defined by
\begin{equation}
  \label{eq:normalmap}
  F^\nor(z) := F(P_X(z)) + z - P_{X}(z).
\end{equation}
A well-known result states that the solution of the VI are  the zeroes of the natural map and are related to the normal map (see \cite{Facchinei.Pang2003}) such that
\begin{equation}
  \label{eq:VI-normalnatural}
  \begin{array}{c}
  x \text{ solves } \mathrm{VI}(X,F) \Longleftrightarrow  F^\nat(x)=0, \\[2mm]
  x \text{ solves } \mathrm{VI}(X,F) \Longleftrightarrow x= P_X(z) \text{ for some } z \text{ such that } F^\nor(z)=0.
\end{array}
\end{equation}
Note that the if $x$ solves  $\mathrm{VI}(X,F)$, it solves also  $\mathrm{VI}(X,\rho F)$ for $\rho > 0$. Therefore, we can define some parametric normal and natural maps by
\begin{equation}
  \label{eq:parametrized-naturalnormalmap}
  \begin{array}{l}
    F_\rho^\nat(z) = z - P_{X}(z-\rho F(z)), \\
    F_\rho^\nor(z) = \rho F(P_X(z)) + z - P_{X}(z).
  \end{array}
\end{equation}
The equivalences (\ref{eq:VI-normalnatural}) continue to hold for the parametric maps. 
 

Using these equivalent nonsmooth equations, the frictional contact problems can be restated as zeroes of nonsmooth functions. Considering the natural map, we obtain for Problem~\ref{prob:I} under the VI form (\ref{eq:vi-I}),
\begin{equation}
  \label{eq:natural-I}
  F_\vione^\nat(v,r) := \left[
  \begin{array}{l}
    \rho (Mv - Hr + f) \\
    r - P_{K}\left(r  - \rho (H^\top v +w  + g(H^\top v +w))\right)
  \end{array}\right] = 0,
\end{equation}
and  for Problem~\ref{prob:II} under the VI form (\ref{eq:vi-II}),
\begin{equation}
  \label{eq:natural-II}
  F_\vitwo^\nat(r) :=   \left[
  \begin{array}{l} 
    r - P_{K}\left(r  - \rho (W r +q + g(W r +q))\right) 
  \end{array}\right] 
  = 0.
\end{equation}
The normal map based formulation are also obtained in the same way. 

In the seminal work of~\cite{Sibony1970}, iterative methods for solving monotone VIs are based the natural map and fixed point iterations. The role of $\rho$ is recognized to be very important for the rate of convergence. To improve the methods, \citet{Sibony1970} proposes to use ``skewed'' projector based on a non-Euclidean metric. Given a positive definite matrix $D\in R^{n\times n}$, a skewed projector $P_{X,D}$ onto $X$ can be defined. For a vector $x\in \RR^n$, the skew projected vector $\bar x  = P_{X,D}(x)$ is the unique solution of the convex program
\begin{equation}
  \label{eq:opt-proj-skew}
  \begin{cases}
    \min\, \Frac 1 2 (y-x)^T D (y-x), \\[2mm]
    \begin{array}{ll}
    s.t. & y \in X .
  \end{array}
  \end{cases}
\end{equation} 
The skew natural map can be also defined and yield the following nonsmooth equation
\begin{equation}
  \label{eq:skew-natural-NE}
   F_D^\nat(z) = z - P_{X,D}(z-D^{-1} F(z)).
\end{equation}
Considering the skew natural map, we obtain for Problem~\ref{prob:I} under the VI form (\ref{eq:vi-I}),
\begin{equation}
  \label{eq:natural-typeI}
  F_{\vione,D}^\nat(v,r) := \left[
  \begin{array}{l}
    D_1^{-1} (Mv - Hr + f) \\ 
    r - P_{K}\left(r  - D_2^{-1} (H^\top v + w  + g(H^\top v + w))\right)
  \end{array}\right] = 0
\end{equation}
with $D_1\in \RR^{n\times n}$ and $D_2\in \RR^{m\times m}$.
For Problem~\ref{prob:II} under the VI form (\ref{eq:vi-II}),
\begin{equation}
  \label{eq:natural-typeII}
  F_{\vitwo,D}^\nat(r) := \left[
  \begin{array}{l} 
    r - P_{K}\left(r  - D^{-1} ( W r +q   + g(Wr+q))\right)  \end{array}\right] = 0
\end{equation}
The previous case is retrieved by choosing $D = \rho^{-1} I_{n\times n}$. 





\begin{ndrva}
  It can be interesting to use something $D$ as a preconditionner of the problem ? $D=diag(W)$ or incomplete LU. Warning, $W$ is only SPD, so we cannot have $D =W$.
\end{ndrva}

\paragraph{Jean--Moreau's and Alart-Curnier's functions}

Using the alternative inclusions formulations~(\ref{eq:signo-inclusion-velo})--(\ref{eq:Coulomb-inclusion}) with a given set of parameters $\rho_\n,\rho_\t$ such that
\begin{equation} 
  \label{eq:inclusion-rhorho}
  \left\{ \begin{array}{ll}
    -\rho_\n u_\n \in N_{\RR^{n_c}_+}(r_\n), & \rho_\n>0, \\
    -\rho_\t u_{\t} \in N_{D(\mu,(r_{n})_+)}(r_\t), & \rho_\t>0,
  \end{array}\right.
\end{equation}
 we can replace $P_K$ into $P_{\RR^{n_c}_+}$ and $P_{D(\mu,(r_{n})_+)}$ where 
\begin{equation}
  \label{eq:diskR-prod}
  D(\mu,(r_{n})_+) = \prod_{\alpha=1\ldots n_c} D(\mu^{\alpha} (r_{\n}^\alpha)_+).
\end{equation}
defines the Cartesian product of the Coulomb disks for each contact. The notation $x_+$ stands for $x_+ = \max(0,x)$. Using this procedure, \citet{Jean.Moreau1987} propose the following nonsmooth equation formulation of the frictional contact condition
\begin{equation}
  \label{eq:Moreau--Jean-1}
    \begin{cases}
    r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n  u_\n) = 0, \\
    r_\t - P_{D(\mu, (r_{\n})_+)}(r_\t - \rho_\t u_\t   )=0.
  \end{cases}
\end{equation}
The parameters $\rho_n,\rho_\t$ may be also chosen contact by contact. Problem~\ref{prob:I} is then reformulated as
\begin{equation}
  \label{eq:MJ-I}
  F_{\mjone}(v,r) := \left[
    \begin{array}{c}
    Mv - Hr - f \\
    r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n (H^\top v + w)_\n) \\
    r_\t - P_{D(\mu, (r_{\n})_+)}(r_\t - \rho_\t (H^\top v + w)_\t   ) 
  \end{array}\right] =0
\end{equation}
and  Problem~\ref{prob:II}  as
\begin{equation}
  \label{eq:MJ-II}
    F_{\mjtwo}(r) := \left[ \begin{array}{c}
    r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n (W r +  q)_\n) \\
    r_\t - P_{D(\mu, (r_{\n})_+)}(r_\t - \rho_\t (Wr+q)_\t   ) 
  \end{array}\right] =0.
\end{equation}
In~\cite{Christensen.Klarbring.ea1998}, the same formulation is used.

 In the seminal work of  Alart \& Curnier~\cite{Curnier.Alart88,Alart.Curnier1991}, the augmented Lagrangian approach is invoked to obtain a  similar formulation motivated by the development of nonsmooth (or generalized) Newton methods (see Sect.~\ref{Sec:NSN-AC} ). To be accurate, the original Alart--Curnier function is given by 
\begin{equation}
  \label{eq:AC-1}
  \begin{cases}
    r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n  u_\n) = 0, \\
    r_\t - P_{D(\mu, (r_\n - \rho u_\n)_+)}(r_\t - \rho_\t u_\t   )=0.
  \end{cases}
\end{equation}
Note that the difference between~(\ref{eq:Moreau--Jean-1}) and (\ref{eq:AC-1}) lies in the formulation disk onto which one project: $D(\mu, (r_\n - \rho u_\n)_+)$ rather than $D(\mu, (r_{\n})_+)$. Problem~\ref{prob:I} and~\ref{prob:II} can be also reformulated as in~(\ref{eq:MJ-I}) and (\ref{eq:MJ-II}) using (\ref{eq:AC-1}). We note the mapping that we get in that way $F_{\acone}(v,u,r)$ and  $F_{\actwo}(v,u,r)$.


Problem~\ref{prob:I} is then reformulated as
\begin{equation}
  \label{eq:AC-I}
  F_{\acone}(v,r) := \left[
    \begin{array}{c}
    Mv - Hr - f \\
    r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n (H^\top v +w)_\n) \\
    r_\t - P_{D(\mu, (r_\n - \rho_\n u_\n)_+)}(r_\t - \rho_\t (H^\top v +w)_\t   )
  \end{array}\right] =0
\end{equation}
and  Problem~\ref{prob:II}  as
\begin{equation}
  \label{eq:AC-II}
    F_{\actwo}(r) := \left[ \begin{array}{c}
    r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n (W r +  q)_\n) \\
    r_\t - P_{D(\mu, (r_\n - \rho_\n u_\n)_+)}(r_\t - \rho_\n (W r +  q)_\t   )
  \end{array}\right] =0.
\end{equation}

\begin{remark}
  From the QVI formulation~(\ref{eq:qvi-1}), the following nonsmooth
  equation can also be written
  \begin{equation}
    \label{eq:qvi-proj}
    r = P_{C(\mu,r_\n)}(r-\rho u)
  \end{equation}
  which exactly corresponds to~(\ref{eq:Moreau--Jean-1}). \texttt{ A verifier}
\end{remark}

\begin{ndrva}
  + understand the continuity comment of Alart ?

  + Simo--Laursen ?

\tb{  + discussion on $(r_\n)_+$ in \ref{eq:diskR-prod} (cf. Olivier comment)}
\end{ndrva}

%In \cite{Leung.ea1998} and \cite{Xuewen.ea2000}, alternative equations reformulations are proposed mainly based on the reformulation of the problem in the plane of sliding.


\paragraph{General SOCC-functions}

More generally, a large family of reformulations of the SOCCP~(\ref{eq:contact-SOCCP}) in terms of equations can be obtained by using a so-called Second Order Cone Complementarity (SOCC) function. Let us consider the following SOCCP over symmetric cone $K^\star = K $. A SOCC-function $\phi$ is defined by
\begin{equation}
  \label{eq:SOCC-function}
  K \ni x \perp y \in K \Longleftrightarrow \phi(x,y)=0.
\end{equation}
The frictional contact problem can be written as a SOCCP over symmetric cones by applying the following transformations
\begin{equation}
  \label{eq:SOCC-function1}
  x = T_x \hat u =
  \begin{bmatrix}
    \hat u_\n \\
    \mu \hat u_{\t}
  \end{bmatrix}
  \text{ and }  y =T_y r
  \begin{bmatrix}
    \mu r_\n \\
    r_\t
  \end{bmatrix}.
\end{equation}

Clearly, the nonsmooth equations of the previous sections provides several examples of SOCC-functions and the natural map offers the most simplest one. In~\cite{Fukushima.ea2001}, the standard complementarity functions for Nonlinear Complementarity Problems (NCP) such as the famous Fischer-Burmeister function are extended to the SOCCP by means of Jordan algebra. Smoothing functions are also given with theirs Jacobians and they studied their properties in view of the application of Newton's method.  For the second order cone, the Jordan algebra can be defined with the following non-associative Jordan product,
\begin{equation}
  \label{eq:Jordan-product}
  x \cdot y =
  \left[\begin{array}{c}
      x^\top y \\
      y_\n x_\t + x_\n y_\t
  \end{array}
\right]
\end{equation}
and the usual componentwise addition $x+y$. The vector $x^2$ denotes $x\cdot x$ and their exists an unique vector $x^{1/2}\in K$ that defines the square root for all $x \in K$ such that
\begin{equation}
  \label{eq:Jordan-sqrt}
  (x^{1/2})^2 = x^{1/2} \cdot x^{1/2} = x.
\end{equation}
A direct calculation yields
\begin{equation}
  \label{eq:Jordan-sqrt2}
  x^{1/2} =
  \left[\begin{array}{c}
    s \\[1mm]
    \Frac {x_\t} {2s}
  \end{array}\right], \quad \text{ where } s = \sqrt{(x_\n+\sqrt{x_\n^2 - \|x_\t\|^2})/2}.
\end{equation}
If $x=0$, we conventionally define $0^{1/2}=0$. The vector $|x| \in K$ denotes $(x^2)^{1/2}$. Thanks to this algebra and its associated operator, the projection onto $K$ can be written as
\begin{equation}
  \label{eq:Jordan-projection}
  P_K(x) = \Frac{x + |x|}2.
\end{equation}
This formula provides a new expression for the natural map and its associated nonsmooth equations. This is exactly what is done in~\cite{Hayashi.ea_SIOPT2005} where the natural map~(\ref{eq:naturalmap}) is used together with an expression of the projection operator based on the Jordan algebra calculus. The SOCCP is then solved with a semi--smooth Newton method and with the help of smoothing.

Most of the calculus in Jordan algebra are based on the spectral decomposition, which is a basic concept in Jordan Algebra (see for more details \cite{Fukushima.ea2001}). For $x = (x_\n, x_\t)\in \RR\times \RR^2$, the spectral decomposition is defined by
\begin{equation}
  \label{eq:Jordan-spectraldecomposition}
  x = \lambda_1 u_1 + \lambda_2 u_2,
\end{equation}
where $\lambda_1,\lambda_2\in \RR$ and $u_1,u_2\in\RR^3$ are the spectral values and the spectral vectors of $x$ given by
\begin{equation}
  \label{eq:Jordan-spectraldecomposition1}
    \lambda_i= x_\n + (-1)^i \|x_\t\|, \quad
    u_i =
    \begin{cases}
      \frac{1}{2}
      \begin{bmatrix}
        1 \\
        (-1)^i \Frac{x_\t}{\|x_\t\|}
      \end{bmatrix}, \text{ if } x_\t\neq 0 \\[5mm]
       \frac{1}{2}
      \begin{bmatrix}
        1 \\
        (-1)^i w
      \end{bmatrix}, \text{ if } x_\t = 0 \\
    \end{cases}, i = 1,2
\end{equation}
with $w\in\RR^2$ being any vector satisfying $\|w\|=1$. Note that if $x_\t\neq 0$ the decomposition is unique. The spectral decomposition enjoys very nice properties that  allows to simplify  the computation of basic functions such that
\begin{equation}
  \label{eq:Jordan-spectraldecomposition2}
  \begin{array}{l}
    x^{1/2} = \sqrt{\lambda_1} u_1 + \sqrt{\lambda_2} u_2, \text{ for any }  x \in K, \\[1mm]
    P_K(x) = \max(0,\lambda_1) u_1 + \max(0,\lambda_2) u_2. 
  \end{array}
\end{equation}




More interestingly,  general C-functions can also be extended and smoothed version of this function can be also developed (see \cite{Fukushima.ea2001}
). Let us start with the Fischer-Burmeister function
\begin{equation}
  \label{eq:Jordan-FB}
  \phi_{\fb}(x,y) = x+y - (x^2 + y^2 )^{1/2}.
\end{equation}
It can shown that the zeroes of $\phi_{\fb}$ are solutions of the SOCCP~(\ref{eq:SOCC-function}) using the Jordan algebra associated with $K$. Using the spectral decomposition, the Fischer-Burmeister function can be computed easily as
\begin{equation}
  \label{eq:Jordan-FB-1}
  \phi_{\fb}(x,y) = x+y - (\sqrt{\bar \lambda_1} \bar u_1 + \sqrt{\bar \lambda_2} \bar u_2)
\end{equation}
where $\bar\lambda_1,\bar\lambda_2\in \RR$ and $\bar u_1,\bar u_2\in\RR^3$ are the spectral values and the spectral vectors of $x^2+y^2$ that is
\begin{equation}
  \label{eq:Jordan-FB-2}
  \begin{array}{rcl}
    \bar \lambda_i&=& \|x\|^2  + \|y\|^2 +   2 (-1)^i\|x_{\n}x_{\t} +y_{\n}y_{\t}\| \\
    \bar u_i &=&
    \begin{cases}
      \frac{1}{2}
      \begin{bmatrix}
        1 \\
        (-1)^i \Frac{x_{\n}x_{\t} +y_{\n}y_{\t}}{\|x_{\n}x_{\t} +y_{\n}y_{\t}\|}
      \end{bmatrix}, \text{ if } x_{\n}x_{\t} +y_{\n}y_{\t}\neq 0 \\[5mm]
       \frac{1}{2}
      \begin{bmatrix}
        1 \\
        (-1)^i w
      \end{bmatrix}, \text{ if } x_{\n}x_{\t} +y_{\n}y_{\t} = 0 \\
    \end{cases}
\end{array}, i = 1,2.
\end{equation}




\paragraph{Fischer-Burmeister function for the frictional contact problem}



\begin{equation}
  \label{eq:FB-II}
   F_{FB}(u,r) =   \left[
     \begin{array}{l} 
       u - W r -q\\
       \Phi_{FB}\left(
       \begin{bmatrix}
         \mu r_\n \\
         r_\t
       \end{bmatrix},
       \begin{bmatrix}
         \frac 1 \mu (u_\n+ \mu \|u_\t\|)\\
         r_\t
       \end{bmatrix}
       \right)
     \end{array}\right] 
   = 0.
\end{equation}
\begin{ndrva}
  TBW
  
  Define $\Phi_FB$ for all contacts
  
  Finally, note that
  \begin{equation}
    \label{eq:equiv}
    K^* \ni x \perp y \in K \Longleftrightarrow K^* \ni x \cdot y \in K
  \end{equation}
  Check there is no troubles with $\mu =0$. This has to be done for all of this section.
\end{ndrva}


\subsection{Alternative  complementarity formulations}

A direct complementarity formulation over the positive orthant can also be written by introducing the following slack variable  $\kappa^\alpha = \|u^\alpha_{\t}\|$ for each contact $\alpha$. With the help of this new variable, the contact law for one contact can be written
\begin{equation}
  \label{eq:MCP}
  \begin{cases}
    \kappa = \|u_{\t}\| \\
    \kappa r_\t + \|r_\t\| u_\t =0\\
    0 \leq \kappa \perp \mu r_\n - \|r_\t\| \geq 0 \\
    0 \leq u_\n \perp r_\n \geq 0.
  \end{cases}
\end{equation}
Together with the linear discretized dynamics, the whole problem can be formulated as an NCP (or MCP) as it is defined in~\cite{Dirkse.Ferris1995}. This formulation enables therefore the use of MCP solvers as the PATH solver for the frictional contact problem. Unfortunately, the fact that the functions involved in the formulation of the MCP are themselves nonsmooth due to the norm prevents a robust application of such solvers. In~\cite{Glocker1999}, another MCP formulation is provided. The attempt to use it in a numerical framework was a success due the redundancy of constraints in the formulation.


In~\cite{Kanno.ea2006},  a alternative second--order cone formulation is proposed by introducing a slack variable $\lambda_\n\in\RR$ for each contact. The disjunctive formulation of the Coulomb contact law is then formulated as
\begin{equation}
  \label{eq:kanno}
    \RR_+\times K_1 \ni
    \begin{bmatrix}
     u_\n \\ \lambda_\n \\  u_{\t}
    \end{bmatrix}
    \perp
    \begin{bmatrix}
     r_\n\\ \mu r_\n \\ r_{\t}
    \end{bmatrix}
    \in \RR_+ \times K_1
\end{equation}
where $K_1 =\{x | \mid  \|x_\t\| \leq x_\n  \}$. In the special that $H$ is the identity matrix (which implies that $n=m$), the linear relations given in Problem~\ref{prob:I} between $u$ and $r$ reduce to $Mv = r +f$ and $u = v+w $. We obtain the following Second Order Cone Linear Complementarity problem (SOCLCP)
\begin{equation}
  \label{eq:kanno1}
  \begin{cases}
    \begin{bmatrix}
      r_\n\\ \mu r_\n \\ r_{\t}
    \end{bmatrix} =
    \begin{bmatrix}
      M_{\n\n} & 0 & M_{\n\t} \\
      \mu M_{\n\n} & 0 & \mu M_{\n\t} \\
      M_{\t\n} & 0 & \mu M_{\t\t} \\
    \end{bmatrix}
    \begin{bmatrix}
      u_\n \\ \lambda_\n \\ u_{\t}
    \end{bmatrix} +
    \begin{bmatrix}
      q_\n \\ \mu q_\n \\ q_{\t}
    \end{bmatrix}
    \\
    \RR_+\times K_1 \ni
    \begin{bmatrix}
     u_\n \\ \lambda_\n \\  u_{\t}
    \end{bmatrix}
    \perp
    \begin{bmatrix}
     r_\n\\ \mu r_\n \\ r_{\t}
    \end{bmatrix}
    \in \RR_+ \times K_1.
  \end{cases}
\end{equation}
The fact that the SOCCP is linear is quite attractive but the strong rank deficiency renders difficult the design of robust numerical algorithms. In \cite{Zhang.ea_CMAME2011}, this formulation is used with the help of a normal and tangential penalization of the contact.


\subsection{Optimization problems}

In this section, several optimization-based formulations are proposed. The quest for an efficient optimization formulation of the frictional problem is an hard task. Since the problem is nonsmooth and nonconvex, the use of an associated optimization problem is interesting from the numerical point of view if we want to improve the robustness and the stability of the numerical methods.

%\subsubsection{A direct optimization problem}

 A straightforward optimization problem can be written whose cost function to minimize is the scalar product $r^\top\hat u$. Indeed, this product is always  positive and vanishes at the solution. Let us consider this first optimization formulation
\begin{equation}
  \label{eq:opt-1}
  \begin{cases}
    \min\,  r^\top \hat u = r^\top u + \sum _{\alpha=1}^{n_c} \mu^\alpha r_\n^\alpha \|u_\t^\alpha\| \\[2mm]
    \begin{array}{ll}
    s.t. &\hat u \in K^\star, \\
    &r \in K,
  \end{array}
  \end{cases}
\end{equation}
which amounts to minimizing the DeSaxc\'e's bipotential function~\cite{DeSaxce92} over $K^\star\times K$. A first simplification can be made by noting that
\begin{equation}
  \label{eq:equiv-cone}
  \hat u \in K^\star \Longleftrightarrow u_{\n} \geq 0, 
\end{equation}
which leads to
\begin{equation}
  \label{eq:opt-2}
  \begin{cases}
    \min\, r^\top u + \sum _{\alpha=1}^{n_c} \mu^\alpha r_\n^\alpha \|u_\t^\alpha\| \\[2mm]
     \begin{array}{ll}
    s.t. &u_\n \geq 0\\
    &r \in K.
  \end{array}
  \end{cases}
\end{equation}


Starting from Problem~\ref{prob:II}, a direct substitution of $u = Wr +q$ yields
\begin{equation}
  \label{eq:opt-3}
  \begin{cases}
    \min\, r^\top (Wr+q) + \sum _{\alpha=1}^{n_c} \mu^\alpha r_\n^\alpha \|(Wr+q)_\t^\alpha\| \\[2mm]
    \begin{array}{ll}
      s.t. &(W r + q){\sf N} \geq 0, \\
      &r \in K.
    \end{array}
  \end{cases}
\end{equation}
which is an nonlinear optimization problem with a nonsmooth and nonconvex cost function.  From the numerical point of view this problem may be very difficult and we have to ensure that the cost function have to be zero at the solution which is not guaranteed of some local minima are reached in the minimization process.

Other optimization-based formulations have been proposed in the literature. They are not direct optimization formulation but they try to identify a optimization sub-problem which is well-posed and for which efficient numerical methods are available. Three approaches can be listed in three categories : a)  the \textit{alternating optimization} problems, b) the \textit{successive approximation} method and c)  the \textit{convex SOCP} approach.


\paragraph{The alternating optimization problems} aims at solving the frictional contact problem by alternatively solving the Signorini condition for a known fixed values of the tangential reaction $r_\t$ and solving the Coulomb friction model for a known fixed values of the normal reaction $r_\n$. 

For Problem~\ref{prob:II}, let us consider the following splitting of the matrix $W$ and the vector $q$
\begin{equation}
  \label{eq:W-split}
  u = W r +q \Longleftrightarrow 
  \left[\begin{array}{c}
    u_\n \\ u_\t
  \end{array}\right]
 =
  \left[\begin{array}{cc}
    W_{\n\n} &W_{\n\t} \\
    W_{\t\n} &W_{\t\t} \\    
  \end{array}\right]    \left[\begin{array}{c}
    r_\n\\ r_\t
  \end{array}\right]+
 \left[\begin{array}{c}
    q_\n \\q_\t
  \end{array}\right].
\end{equation}
Two sub-problems can therefore be identified : the first problem for the normal part is to find $u_\n$ and $r_\n$ such that
\begin{equation}
  \label{eq:AO-1}
  \begin{cases}
    u_\n = W_{\n\n} r_\n + \tilde q_\n, \\
    0\leq u_\n \perp r_\n \geq 0,
  \end{cases}
\end{equation}
with a given value of $\tilde q_\n = q_\n + W_{\n\t}r_\t$ and the second problem for the tangent part is to find $u_\t$ and $r_\t$ such that
\begin{equation}
  \label{eq:AO-2}
  \begin{cases}
    u_\t = W_{\t\t} r_\t + \tilde q_\t, \\
   -u_\t \in N_{D(\mu,\tilde r_{\n})}(r_\t),
  \end{cases}
\end{equation}
with  given values of $\tilde r_\n$ and $\tilde q_\t = q_\t + W_{\t\n}r_n$. Since $W$ is a symmetric positive semi--definite  matrix, $W_{\n\n}$ and $W_{\t\t}$ are also symmetric semi--definite positive matrices. Two convex optimization problems can therefore be formulation as
 \begin{equation}
  \label{eq:AO-3}
  \begin{cases}
    \min\, \Frac 1 2 r_\n^\top  W_{\n\n} r_\n + r_n^\top \tilde q_\n, \\
    \begin{array}{ll}
    \text{s.t.} & r_\n \geq 0,
  \end{array}\end{cases}
\end{equation}
and
\begin{equation}
  \label{eq:AO-4}
  \begin{cases}
    \min\,  \Frac 1 2 r_\t^\top W _{\t\t} r_\t +  r_\t^\top \tilde q_\t, \\
    \begin{array}{ll}
     \text{s.t.}  & r_\t \in D(\mu,\tilde r_{\n}).
  \end{array}
\end{cases}
\end{equation}
Problem~\ref{prob:I} is treated in the same manner by splitting the matrix $H$ and the vector $w_\n$ such that
\begin{equation}
  \label{eq:H-split}
  u = H^\top v +w \Longleftrightarrow  \left[\begin{array}{c}
    u_\n \\ u_\t
  \end{array}\right]
 =
  \left[\begin{array}{c}
      H_{\n} \\
      H_{\t} \\    
    \end{array}\right]^\top   \, v+
 \left[\begin{array}{c}
    w_\n \\w_\t
  \end{array}\right].
\end{equation}
We get for the normal part
\begin{equation}\label{eq:soccp1-normal}
  \begin{cases}
    M v = {H_\n} {r_\n} + {\tilde f_\n} \\[2mm]
    u_\n = H_\n^\top v + w_\n \\[2mm]
    0 \leq { u_\n} \perp r _\n \geq 0
  \end{cases}
\end{equation}
for  given value of $\tilde r_\t$ and $\tilde f_\n = f + H_\t r_\t$. Since $M$ is a symmetric positive definite matrix, an equivalent convex optimization can be written
\begin{equation}
  \label{eq:soccp1-normal-min}
    \begin{cases}
    \min\, \frac 1 2 v^\top M v + v^\top \tilde f_\n  \\[2mm]
     \begin{array}{ll}
    s.t. & H_\n^\top v + w_\n \geq 0
  \end{array}
  \end{cases}
\end{equation}
and $u_\n$ is obtained by $ u_n = H_\n^\top v + w_\n $ and $r_\n$ is the Lagrange multiplier associated with the constraints. For the tangent part, the situation is a little bit more complicated since we get
\begin{equation}\label{eq:soccp1-tangent}
  \begin{cases}
    M v = {H_\t} {r_\t} + {\tilde f_\t} \\[2mm]
    u_\t = H_\t^\top v + w_\t \\[2mm]
    -u_\t \in N_{D(\mu,\tilde r_{\n})}(r_\t),
  \end{cases}
\end{equation}
for  given value of  $\tilde r_\n$ and $\tilde f_\t = f + H_\n \tilde r_\n$. It is therefore difficult to associate an optimization which differs from~(\ref{eq:AO-4}).  

%  Since $M$ is a symmetric positive definite matrix, an equivalent convex optimization can be written
% \begin{equation}
%   \label{eq:soccp1-tangent-min}
%     \begin{cases}
%     \min\, \frac 1 2 v^\top M v + v^\top \tilde f_\t  \\[2mm]
%      \begin{array}{ll}
%     s.t. & u_\t = H_\t^\top v + w_\t
%   \end{array}
%   \end{cases}
% \end{equation}
% and $u_\n$ is obtained by $ u_n = H_\n^\top v + w_\n $ and $r_\n$ is the Lagrange multiplier associated with the constraints.


\texttt{citer Panagiotopoulos + remark Olivier}

\paragraph{The successive approximation} method identifies a single optimization problem by introducing a function that maps the normal reaction to itself (or the friction threshold) such that
\begin{equation}
  \label{eq:Haslinger-g}
  h(r_\n)  = r_\n
\end{equation}
Using this artifact, we can define a new problem from Problem~\ref{prob:II} such that
\begin{equation}
  \label{eq:Haslinger-1}
  \begin{cases}
    \theta = h(r_\n) \\
    u = W r + q \\
    -u_{\n} \in N_{\RR^{n_c}_+}(r_\n) \\
    -u_{\t} \in N_{D(\mu,\theta)}(r_\t)
  \end{cases}
\end{equation}
Since W is a symmetric positive semi-definite  matrix, the last three lines are equivalent to a convex optimization problem over the product of cylinder $C(\mu,\theta)$, that is
\begin{equation}
  \label{eq:Haslinger-2}
  \begin{cases}
    \theta = h(r_\n) \\[2mm]
    \min\, \Frac 1 2 r^\top W r + r^\top q \\
    \begin{array}{ll}
    \text{s.t. }& r \in C(\mu,\theta)
  \end{array}
  \end{cases}
\end{equation}

The method of successive approximation has been extensively used for proving existence and uniqueness of solutions to the discrete frictional contact problems. We refer to~\cite{Haslinger.ea1996} which summarizes the seminal work of the Czech school~\cite{Necas.ea1980,Haslinger1983,Haslinger1984}. We will see in the sequel that this approach also provides us with very efficient numerical solvers.

\paragraph{ The convex SOCP} approach operates in the same vein but a  SOCQP sub-problem is identified. To this aim, we use the function $g(u)$ introduced in~(\ref{eq:modified-bis}) and thanks to this mapping we rewrite Problem~\ref{prob:II} as
\begin{equation}\label{eq:ACLM-2}
  \begin{cases}
    s = g(u) \\[2mm]
    \hat u = W r + q + s  \\[2mm]
    K^\star \ni {\hat u} \perp r \in K.
  \end{cases}
\end{equation} 
Since $W$ is a positive semi-definite matrix, a new convex optimization sub-problem can be defined 
\begin{equation}\label{eq:ACLM-3}
  \begin{cases}
    s = g(u) \\[2mm]
    \left\{
      \begin{array}{ll}
        \min\,&\Frac 1 2 r^\top W r + r^\top (q + s)  \\
        \text{s.t. } & r \in K.
      \end{array}
    \right.
  \end{cases}
\end{equation} 
Problem~\ref{prob:I} may be also reformulated in this form
\begin{equation}\label{eq:ACLM-4}
  \begin{cases}
    s = g(u) \\[2mm]
    \left\{
      \begin{array}{ll}
        \min\,&\Frac 1 2 v^\top M v -  f^\top v  \\
        \text{s.t. } & H v  + w + s  \in K^\star.
      \end{array}
    \right.
  \end{cases}
\end{equation} 
In this latter formulation, the optimization sub--problem appears as a strictly convex optimization problem ($M$ is assumed to be semi--definite positive) under (possibly redundant) cone constraints. If this sub--problem is feasible, the sub--problem admits a unique solution. This formulation introduced in~\cite{Cadoux2009} and developped in~\cite{Acary.Cadoux2013,Acary.ea_ZAMM2011} has been used to give an existence criteria to the discrete frictional contact problems. Furthermore, this existence criteria can be numerically checked. 
\clearpage
\section{Numerical methods for VIs}
\label{sec:numericalmethods,vi}


\subsection{Basic fixed point  and projection methods for VI}

Starting from the VI formulations~(\ref{eq:vi}) or more precisely an associated nonsmooth equation through the natural map,
\begin{equation}
  \label{eq:skew-natural-NE-bis}
   F_D^\nat(z) = z - P_{X,D}(z-D^{-1} F(z)).
\end{equation}
A basic idea of algorithm is to perform fixed point iterations on the mapping
\begin{equation}
  \label{eq:skew-fixed-point}
   z \mapsto P_{X,D}(z-D^{-1} F(z)).
\end{equation}
yielding to Algorithm~\ref{Algo:FP-vi} with the specific choice of $D=1/\rho_k \, I$. The choice of the updating rule of $\rho_k$ will be detailed in Section~\ref{sec:numericalmethods,vi,adaptive}.

\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$ Data of VI~(\ref{eq:vi})
      \REQUIRE $\sf z_0$ initial values and $\sf tol >0$ a tolerance
      \REQUIRE $\rho_0$ initial value for $\rho$
      \ENSURE  $\sf z$ solution of VI~(\ref{eq:vi})
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE Update the value of $\rho_k$
      \STATE $\sf z_{k+1} \leftarrow P_{X}(z_k - \rho_k\,F(z_k))$
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$
      \ENDWHILE
      \STATE $\sf z \leftarrow z_{k}$ 
    }
  \end{algorithmic}
  \caption{Fixed point iterations for the VI~(\ref{eq:vi})}  \label{Algo:FP-vi}
\end{algorithm}


Applying the Algorithm~\ref{Algo:FP-vi} to the VI formulation (\ref{eq:vi-I}) leads to the following iteration
\begin{equation}
  \label{eq:FP-vi-I}
  \begin{cases}
    v_{k+1} \leftarrow  v_k - D_1^{-1}( M v_{k} - H r_k +f) \\
    u_{k+1} \leftarrow  u_k - D_2^{-1}( u_k - H^\top v_{k} - w) \\ 
    r_{k+1} \leftarrow  P_{K,D_3}(r_k - D_3^{-1}(u_k +  g(u_k))).
  \end{cases}
\end{equation}
Due to the fact that $u$ is explicitly given as a function of $v$, $D_2$ is chosen as the identity matrix and $u_{k+1}$ plays the role of $u_k$ in the last equation. The following iteration is obtained
\begin{equation}
  \label{eq:FP-vi-Ibis}
  \begin{cases}
    v_{k+1} \leftarrow  v_k - D_1^{-1}( M v_{k} - H r_k +f) \\
    r_{k+1} \leftarrow  P_{K,D_3}(r_k - D_3^{-1}(H^\top v_k + w +  g(H^\top v_k+ w ))).
  \end{cases}
\end{equation}
For the formulation (\ref{eq:vi-II}), the following iterations are performed
\begin{equation}
  \label{eq:FP-vi-II}
  %\begin{cases}
       r_{k+1} \leftarrow  P_{K,D}(r_k - D^{-1}( W r_k + q +  g(W r_k + q ))).
  %\end{cases}
\end{equation}
 In the sequel when a parameter $\rho$ is specified, it is assumed that $D$ is chosen as $1/\rho$ times the identity matrix.


% Algorithms~\ref{Algo:FP-vi-I} and~\ref{Algo:FP-vi-I}.
% \begin{algorithm}
%   \label{Algo:FP-vi-I}
%   \begin{algorithmic}
%     {\sf
%       \STATE $ $
%       \REQUIRE $\sf M,H,f,w,\mu$ Data of Problem~\ref{prob:I}
%       \REQUIRE $\sf D_1,D_2$ two symmetric positive definite matrices
%       \REQUIRE $v_0,r_0$ initial values and $\sf tol >0$ a tolerance
%       \ENSURE  $\sf u,v,r$ solution of Problem~\ref{prob:I}
%       \STATE   $\sf k \leftarrow 0$ 
%       \WHILE {$\sf error > tol$} 
%       \STATE $\sf v_{k+1} \leftarrow  v_k - D_1^{-1}( M v_{k} - H r_k +f)$
%       \STATE $\sf r_{k+1} \leftarrow P_{K,D_2}(r_k - D_2^{-1}(H^\top v_k + w  + g(H^\top v_k + w)))$
%       \STATE Evaluate $\sf error$.
%       \STATE $\sf k \leftarrow k+1$
%       \ENDWHILE
%       \STATE $\sf v \leftarrow v_{k},\quad \sf r \leftarrow r_{k}$ 
%       \STATE $\sf u \leftarrow H^\top v_k + w $
%     }
%   \end{algorithmic}
%   \caption{Fixed point iterations on Problem~\ref{prob:I} based on VI~(\ref{eq:vi-I})}
% \end{algorithm}
% \begin{algorithm}
%   \label{Algo:FP-vi-II}
%   \begin{algorithmic}
%     {\sf
%       \STATE $ $
%       \REQUIRE $\sf W,q,\mu$ Data of Problem~\ref{prob:II}
%       \REQUIRE $\sf D$ a symmetric positive definite matrix
%       \REQUIRE $r_0$ initial values and $\sf tol >0$ a tolerance
%       \ENSURE  $\sf u,r$ solution of Problem~\ref{prob:II}
%       \STATE   $\sf k \leftarrow 0$ 
%       \WHILE {$\sf error > tol$} 
%       \STATE $\sf r_{k+1} \leftarrow P_{K,D_2}(r_k - D^{-1}(W r_k + q + g(W r_k + q)))$
%       \STATE Evaluate $\sf error$.
%       \STATE $\sf k \leftarrow k+1$
%       \ENDWHILE
%       \STATE $\sf  r \leftarrow r_{k}$ 
%       \STATE $\sf u \leftarrow H^\top v_k + w $
%     }
%   \end{algorithmic}
%   \caption{Fixed point iterations on Problem~\ref{prob:II} based on VI~(\ref{eq:vi-II})}
% \end{algorithm}
The convergence of such methods are generally demonstrated for strongly monotone VI. For the problems we are concerned, this assumption is not satisfied, but we will see in the sequel that such methods can converge in practical numerical applications. 
Algorithm~\ref{Algo:FP-vi} with the iteration rule~(\ref{eq:FP-vi-II}) and a fixed value of $\rho_k$ has been originally proposed in \cite{DeSaxce.Feng1998}. The algorithm is called Uzawa's algorithm by reference to the algorithm due to Uzawa in computing the optimal values of convex program by primal-dual techniques.



Using the other nonsmooth equations~(\ref{eq:Moreau--Jean-1}) and (\ref{eq:AC-1}) or the QVI formulation~(\ref{eq:qvi-II}), similar algorithms can be derived. For QVI~(\ref{eq:qvi}), we perform fixed point iterations on the mapping
\begin{equation}
  \label{eq:skew-fixed-point-qvi}
   z \mapsto P_{X(z),D}(z-D^{-1} F(z)).
\end{equation}
yielding to Algorithm~\ref{Algo:FP-qvi}. 
\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$ Data of VI~(\ref{eq:vi})
      \REQUIRE $z_0$ initial values and $\sf tol >0$ a tolerance  
      \REQUIRE $\rho_0$ initial value for $\rho$
      \ENSURE  $\sf z$ solution of VI~(\ref{eq:vi})
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE Update the value of $\rho_k$
      \STATE $\sf z_{k+1} \leftarrow P_{X(z_k)}(z_k - \rho_k\,F(z_k))$
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$
      \ENDWHILE
      \STATE $\sf z \leftarrow z_{k}$ 
    }
  \end{algorithmic}
  \caption{Fixed point iterations for the QVI~(\ref{eq:qvi})}  \label{Algo:FP-qvi}
\end{algorithm}
For Problem~\ref{prob:II} and~(\ref{eq:Moreau--Jean-1}), we get the following iteration rule
\begin{equation}
  \label{eq:FP-MJ-II}
  \begin{cases}
    u_{k+1} \leftarrow W r_{k} +q\\
    r_{\n,k+1} \leftarrow P_{\RR^{n_c}_+}(r_{\n,k} -\rho_\n u_{\n,k+1}) \\
    r_{\t,k+1} \leftarrow P_{D(\mu,r_{\n,k})}(r_{\t,k}-\rho_\t u_{\t,k+1})
  \end{cases}
\end{equation}
and with the ~(\ref{eq:AC-1}), we get
\begin{equation}
  \label{eq:FP-AC-II}
  \begin{cases}
    u_{k+1} \leftarrow W r_{k} +q\\
    r_{\n,k+1} \leftarrow P_{\RR^{n_c}_+}(r_{\n,k} -\rho_\n u_{\n,k+1}) \\
    r_{\t,k+1} \leftarrow P_{D(\mu,r_{\n,k}-\rho_\n u_{\n,k+1} )}(r_{\t,k}-\rho_\t u_{\t,k+1})
  \end{cases}
\end{equation}
We will see in Section~\ref{Sec:OptimisationBasedMethods} that more evolved algorithms can be written exploiting the structure of the convex optimization sub-problems.


% Algorithm~\ref{Algo:FP-MJ-II}. For the tangential part, the projection is performed on $D(\mu,r_{\n,k})$ at the iteration $k$. It can be also performed on  $D(\mu,r_{\n,k+1})$. We will see in Section~\ref{Sec:OptimisationBasedMethods} that more evolved algorithms can be written exploiting the convex optimization sub-problems
% \begin{algorithm}
%   \label{Algo:FP-MJ-II}
%   \begin{algorithmic}
%     {\sf
%       \STATE $ $
%       \REQUIRE $\sf W,q,\mu$ Data of Problem~\ref{prob:II}
%       \REQUIRE $\sf \rho_\n,\rho_t$ user-defined (scalar or vector) parameters
%       \REQUIRE $r_0$ initial values and $\sf tol >0$ a tolerance
%       \ENSURE  $\sf u,r$ solution of Problem~\ref{prob:II}
%       \STATE   $\sf k \leftarrow 0$ 
%       \WHILE {$\sf error > tol$} 
%       \STATE $\sf u_{k+1} \leftarrow W r_{k} +q $
%       \STATE $\sf r_{\n,k+1} \leftarrow P_{\RR^{n_c}_+}(r_{\n,k} -\rho_\n u_{\n,k+1})$
%       \STATE $\sf r_{\t,k+1} \leftarrow P_{D(\mu,r_{\n,k})}(r_{\t,k} -\rho_\t u_{\t,k+1})$
%       \STATE Evaluate $\sf error$.
%       \STATE $\sf k \leftarrow k+1$
%       \ENDWHILE
%       \STATE $\sf  r \leftarrow r_{k}$ 
%       \STATE $\sf u \leftarrow W r_{k} +q$
%     }
%   \end{algorithmic}
%   \caption{Fixed point iterations on Problem~\ref{prob:II} based on nonsmooth equations~(\ref{eq:Moreau--Jean-1})  }
% \end{algorithm}
\begin{ndrva}
  More interesting in alternating context because we have two convex sub-problems.
\end{ndrva}

\paragraph{Extragradient methods}

The extragradient method~\citep{Korpelevich1976} is also a well-known method for VI which improves the previous projection method.  It can be described as
\begin{equation}
  \label{eq:vi-ge5}
  \begin{array}{lcl}
    \bar z_{k} &\leftarrow& P_X(z_k-\rho F(z_k))\\
    z_{k+1} &\leftarrow& P_X(z_{k}-\rho\,F(\bar z_k))
  \end{array}
\end{equation}
and formulated in Algorithm~\ref{Algo:ExtraGradient-vi}.
\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$ Data of VI~(\ref{eq:vi})
      \REQUIRE $z_0$ initial values and $\sf tol >0$ a tolerance
      \ENSURE  $\sf z$ solution of VI~(\ref{eq:vi})
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE Update the value of $\rho_k$
      \STATE $\sf \bar z_{k} \leftarrow P_X(z_{k}-\rho_k F(z_k))$
      \STATE $\sf z_{k+1} \leftarrow P_X(z_{k}-\rho_k\,F(\bar z_k))$
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$
      \ENDWHILE
      \STATE $\sf z \leftarrow z_{k}$ 
    }
  \end{algorithmic}
  \caption{Extragradient method for the VI~(\ref{eq:vi})}  \label{Algo:ExtraGradient-vi}
\end{algorithm}
The convergence of this method requires  that the function $F$ is Lipschitz--continuous and pseudo--monotone and that a solution exists. 

In~\citep{He.Liao_JOTA2002}, the extragradient method is reinterpreted as a prediction-correction method applied to the proximal point algorithm. Indeed, the proximal point algorithm amounts to solving the following VI for a given $z_k$
\begin{equation}
  \label{eq:PPA-VI1}
  ((z-z_k)+ \alpha_k F(z))^\top(y-z) \geq 0, \text{ for all } y \in X \text{ and } \alpha_k >0
\end{equation}
or equivalently
\begin{equation}
  \label{eq:PPA-VI2}
  z = P_{X}(z - [z - z_k + \alpha_k F(z)]) = P_{X}( z_k - \alpha_k F(z)).
\end{equation}
Searching for a solution $z_{k+1}$ of~(\ref{eq:PPA-VI2}) yields
\begin{equation}
  \label{eq:PPA-VI3}
  z_{k+1} = P_{X}( z_k - \alpha_k F(z_{k+1})])
\end{equation}
which can be viewed as a implicit version of the basic fixed point iteration based on~(\ref{eq:skew-fixed-point-qvi}). A prediction--correction method based may be written as 
\begin{equation}
  \label{eq:PPA-VI4}
  \begin{array}{lcl}
    \bar z_{k} &\leftarrow& P_X(z_k-\rho_k F(z_k))\\
    z_{k+1} &\leftarrow& P_X(z_{k}-\alpha_k\,F(\bar z_k))
  \end{array}
\end{equation}
where $\alpha_k$ and $\rho_k$ have to be updated at each iteration.

\paragraph{Projection and contraction methods} The extragradient method needs to projection on $X$ per iteration. In order to improve the basic fixed point method but with only one projection per step, \citet{Solodov.Tseng1996} and \citet{He_AMO1997} consdider
\begin{equation}
  \label{eq:VI-ProjectionContraction1}
  z_{k+1}\leftarrow z_k- \gamma(z_k,\rho) D^{-1}\left[T_{\rho}(z_k)-T_{\rho}(P_X(z_k-\rho F(z_k)) )\right],
\end{equation}
where $D\in \nbR^{n\times n}$ is a PD matrix and  $T_\rho=I-\rho F$. The goal is to choose $\rho \in (0,+\infty)$ sufficiently small so that $T_\rho$ is a strongly monotone mapping. Substituting the expression of $T_\rho$ in~(\ref{eq:VI-ProjectionContraction1}), we get
\begin{equation}
  \label{eq:VI-ProjectionContraction2}
  \begin{array}{lcl}
    \bar z_{k} &\leftarrow& P_X(z_k-\rho F(z_k))\\
    z_{k+1} &\leftarrow& z_k - \gamma(z_k,\rho) D^{-1}\left[z_k-\bar z_k - \rho( F(z_k)- F(\bar z_k))\right].
  \end{array}
\end{equation}
With the analogy with a gradient method,  the search direction $d(z,\rho))$ may be introduced
\begin{equation}
  \label{eq:VI-projectionContraction3}
    d(z,\rho) = z- P_X(z-\rho F(z))  - \rho (F(z) - F(P_X(z-\rho F(z)))) 
  \end{equation}
The method (\ref{eq:VI-ProjectionContraction2}) can be written as 
\begin{equation}
  \label{eq:VI-projectionContraction4}
  \begin{array}{lcl}
    \bar z_{k} &\leftarrow& P_X(z_k-\rho F(z_k))\\
    d_k  &\leftarrow&  z_k - \bar z_k - \rho (F(z_k) - F(\bar z_k)) \\
    z_{k+1} &\leftarrow & z_k - \gamma(z_k,\rho) D^{-1} d_k.
  \end{array}
\end{equation}
where the function $\gamma(z,\rho)$ appears as a step-length in the search direction.
In~\citep{He_AMO1997}, the matrix $D=I$ is the identity matrix and the step-size is chosen as
\begin{equation}
  \label{eq:VI-projectionContraction5}
  \begin{array}{lcl}
    \gamma (z,\rho) = \Frac{\theta [ z - P_X(z-\rho F(z)) ]^\top d(z,\rho)}{\|d(z,\rho)\|^2}, \theta \in (0,2).
  \end{array}
\end{equation}
with the parameter $\rho$ such that
\begin{equation}
  \label{eq:VI-projectionContraction6}
  \begin{array}{lcl}
    \rho \|F(z_k) - F(\bar z_k)\| \leq L \|z_k - \bar z_k\|, \text{ with } L \in (0,1)
  \end{array}
\end{equation}
In~\citep{Solodov.Tseng1996}, the step-size is chosen as
\begin{equation}
  \label{eq:VI-projectionContraction7}
  \begin{array}{lcl}
    \gamma (z,\rho) = \Frac{\theta (1-L) \| z - P_X(z-\rho F(z))\|^2} {\|P^{1/2}d(z,\rho)\|^2}, \theta \in (0,2), L\in (0,1),
  \end{array}
\end{equation}
with the parameter $\rho$ such that
\begin{equation}
  \label{eq:VI-projectionContraction8}
  \begin{array}{lcl}
    \rho (z_k-\bar z_k)(F(z_k) - F(\bar z_k) \leq L \|z_k - \bar z_k\|^2, \text{ with } L \in (0,1)
  \end{array}
\end{equation}
The resulting algorithm is described in Algorithm~\ref{Algo:ProjectionContraction-vi}. The updating rule for $\rho_k$ is will detailed in Section~\ref{sec:numericalmethods,vi,adaptive} in order to satisfy the conditions~(\ref{eq:VI-projectionContraction6}) or~(\ref{eq:VI-projectionContraction8}).


\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$ Data of VI~(\ref{eq:vi})
      \REQUIRE $\sf D$ a symmetric positive definite matrix
      \REQUIRE $z_0$ initial values and $\sf tol >0$ a tolerance
      \ENSURE  $\sf z$ solution of VI~(\ref{eq:vi})
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE Update the value of $\rho_k$ satisfying~(\ref{eq:VI-projectionContraction6}) or~(\ref{eq:VI-projectionContraction8})
      \STATE $\sf \bar z_{k} \leftarrow P_X(z_k-\rho_k F(z_k))$
      \STATE $\sf d_k  \leftarrow  z_k - \bar z_k - \rho_k (F(z_k) - F(\bar z_k)) $
      \STATE $\sf \gamma_k \leftarrow \gamma(z_k,\rho_k)$ with (\ref{eq:VI-projectionContraction5}) or~(\ref{eq:VI-projectionContraction7})
      \STATE $\sf z_{k+1} \leftarrow  z_k - \gamma_k D^{-1} d_k$
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$
      \ENDWHILE
      \STATE $\sf z \leftarrow z_{k}$ 
    }
  \end{algorithmic}
  \caption{Projection and Contraction method for the VI~(\ref{eq:vi})}  \label{Algo:ProjectionContraction-vi}
\end{algorithm}

Other more evolved projected iterative methods can be found in~\citep{He.ea_COA2012-I,He.ea_COA2012-II}.

\paragraph{Hyperplane projection method}
The hyperplane projection method has been introduced by \citep{Konnov1993}. The convergence has been proved under the assumptions that $F$ is  a continuous pseudo-monotone mapping. The method is described in Algorithm~\ref{Algo:HPA}.
\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$
      \REQUIRE $\sf z_0 \in X, \tau >0, \sigma \in (0,1)$
      \ENSURE  $\sf z$ solution of $\sf \mathrm{VI}(X,F)$ with $F$ a continuous pseudo-monotone mapping
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE $\sf y_k \leftarrow  P_X(z_k-\tau F(z_k))$
      \STATE (Armijo line--search) Find the smallest integer, $\sf i\in \nbN$ such that 
      \begin{equation}
        \label{eq:HPA1}
        \sf  F(2^{-i}y_k+(1-2^{-i})z_k)^T (z_k-y_k) \geq \Frac \sigma \tau \|z_k-y_k\|^2
      \end{equation}
      \STATE $\sf i_k \leftarrow i$
      \STATE $\sf x^k \leftarrow 2^{-i_k}y_k+(1-2^{-i_k})z_k$
      \STATE $\sf w_k \leftarrow  z_k - \Frac{F(x_k)^T(z_k-x_k)}{\|F(x_k)\|^2}\,F(x_k)$
      \STATE $\sf z_{k+1}  \leftarrow P_{X}(w_k)$
      \STATE $\sf k \leftarrow k+1$
      \STATE Evaluate $\sf error$.
      \ENDWHILE
    }
  \end{algorithmic}
  \caption{Hyperplane projection method \citep{Konnov1993}}  \label{Algo:HPA}
\end{algorithm}

\subsection{Self-adaptive step-size rules}
\label{sec:numericalmethods,vi,adaptive}

In~\citep{Khobotov_CMMP1987}, a method is proposed to improve the extragradient method of~\citet{Korpelevich1976} by adapting $\rho_k$ is the following way. The goal is the find $\rho_k$ that satisfies
  \begin{equation}
    \label{eq:khobotov1}
    0 < \rho_k \leq \min\left\{\bar\rho,L \Frac{\|z_k-\bar z_k\|}{\|F(z_k)-F(\bar z_k)\|}\right\}\text{ with } L \in (0,1)
  \end{equation}
where $\bar \rho$ is the maximum value of $\rho_k$ which is chosen in the light of the specific problem.  The goal is clearly to find a coefficient that is bounded by the local Lipschitz constant. The standard way to do that is to use a Armijo--type procedure by successively trying value of $\rho_k = \bar \rho \nu^m$ with $m\in\NN$ and $\nu\in (0,1)$. The parameter $\nu$ is typically chosen as $2/3$.  In the original paper of \cite{Khobotov_CMMP1987}, there is no procedure to size $\bar \rho$ or to update it. In~\cite{He.Liao_JOTA2002} and in the context of prediction--correction, the author proposes to use the rule $\rho_k =  \rho_{k-1} \nu^m$ and  if the criteria~(\ref{eq:khobotov1}) is largely satisfied for $\rho_{k}$, the value is increased.
In~\citep{Han.Lo_CMA2002},  a similar procedure is used for the extragradient method by the increasing step of $\rho_k$ is done after the correction as in~\cite{He.Liao_JOTA2002}.
 The criteria~(\ref{eq:khobotov1}) is  verified by computing the ratio
\begin{equation}
  \label{eq:Khobotov-r}
  r _{k} \leftarrow \Frac{\rho_k \|F(z_k)-F(\bar z_k)\|}{ \|z_k-\bar z_k\| }.
\end{equation}
 In~\citep{Solodov.Tseng1996}, similar Armijo--like technique is used. Nevertheless, the ratio $r_k$ is computed as follows:
\begin{equation}
  \label{eq:SolodovTseng-r}
  r _{k} \leftarrow \Frac{\rho_k(z_k-\bar z_k)^\top(F(z_k)-F(\bar z_k))}{ \|z_k-\bar z_k\|^2 }.
\end{equation}
In~\cite{Han.Sun_CMA2004}, the ration $r_k$ is evaluated as
\begin{equation}
  \label{eq:HanSun-r}
  r _{k} \leftarrow \Frac{\rho_k \|z_k-\bar z_k\|^2 }{(z_k-\bar z_k)^\top(F(z_k)-F(\bar z_k))}.
\end{equation}
but in practice this choice appears to be the worth one. 


  The approach is summarized in Algorithm~\ref{Algo:Up1}. The parameter $L$ typically chosen around $0.9$ is a safety coefficient in the evaluation of $\rho_k$. The parameter $L_{min}$ that implies a increase of $\rho_k$ is chosen around $0.3$.
In~Algorithm~\ref{Algo:Up1}, a Boolean option is added to the standard Armijo approach. The approximation $\bar z_k$ is updated within the self--adaptive loop. This trick is not justifies by any theoretical argument and is most of the paper this operation is not performed but in pratice (see Section ~\ref{Sec:Comparison,VI,step-length}) it appears to improve the convergence speed.
 The update of the Armijo rule $\rho_k \leftarrow \nu \,\rho_k$ can also be replaced by  $\rho_k \leftarrow \nu \,\rho_k\, \min\left\{1, 1/r_k\right\}$ but it appears that this trick does improve the self--adaptive procedure. Other more evolved step--lengths strategies can be found in \citep{Wang_JCAM2010} that have been tried in this study.

\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$
      \REQUIRE Search and safety parameters. $\sf L \in (0,1), 0< L_{min} < L, \nu \in (0,1)$
      \REQUIRE $\sf isUpdateInTheLoop$ Boolean option
      \REQUIRE Initial values $\sf z_k \in X, \rho_{k-1} >0$
      \STATE $\sf \rho_k \leftarrow \rho_{k-1}$
      \STATE $\sf \bar z_{k} \leftarrow P_X(z_k-\rho_k F(z_k))$
      \STATE Evaluate $r_k$ with (\ref{eq:Khobotov-r}) (or (\ref{eq:SolodovTseng-r}))
      \WHILE {$\sf  r_k > L $} 
      \STATE $\sf \rho_k \leftarrow \nu \,\rho_k$ 
      \IF {isUpdateInTheLoop}
      \STATE $\sf \bar z_{k} \leftarrow P_X(\bar z_k-\rho_k F(\bar z_k))$
      \ELSE
      \STATE $\sf \bar z_{k} \leftarrow P_X(z_k-\rho_k F(z_k))$
      \ENDIF
      \STATE Evaluate $r_k$ with (\ref{eq:Khobotov-r}) (or (\ref{eq:SolodovTseng-r}))
      \ENDWHILE
      \STATE Perform the correction step of extragradient or prediction--correction method.
      \IF {$\sf r_k < L_{min}$}
      \STATE $\sf \rho_k = \frac 1 \nu \rho_k$ 
      \ENDIF
    }
  \end{algorithmic}
  \caption{Updating rule for $\rho_k$}  \label{Algo:Up1}
\end{algorithm}

\subsection{Naming convention}
\begin{table}
  \centering
  \begin{tabular}{|l|p{0.7\textwidth}|l|}
    \hline
    { Algorithm}
    & Description 
    & parameters\\
    \hline
    \sf FP-DS
    &  Algorithm~\ref{Algo:FP-vi} with the iteration rule~(\ref{eq:FP-vi-II}) and fixed $\rho$
    & $\rho$ \\
    %\hline
    % \sf FP-VI-1 
    % &  Algorithm~\ref{Algo:FP-vi} with the iteration rule~(\ref{eq:FP-vi-Ibis})
    % & $D$ or $\rho$\\
    \hline
    \sf FP-QVI-MJ
    &  Algorithm~\ref{Algo:FP-qvi} with the iteration rule~(\ref{eq:FP-MJ-II}) and fixed $\rho_\n,\rho_\t$
    & $\rho_\n,\rho_\t$\\
     \hline
    \sf FP-QVI-AC 
    &  Algorithm~\ref{Algo:FP-qvi} with the iteration rule~(\ref{eq:FP-AC-II}) and fixed $\rho_\n,\rho_\t$
    & $\rho_\n,\rho_\t$\\
    \hline
    \sf FP-VI-UPK
    &  Algorithm~\ref{Algo:FP-vi} with the iteration rule~(\ref{eq:FP-vi-II}) and Algorithm~\ref{Algo:Up1} with (\ref{eq:Khobotov-r}) 
    & $L, L_{\min}, \nu $ {\sf isUpdateInTheLoop}\\
    \hline
    \sf FP-VI-UPTS
    &  Algorithm~\ref{Algo:FP-vi} with the iteration rule~(\ref{eq:FP-vi-II}) and Algorithm~\ref{Algo:Up1} with (\ref{eq:SolodovTseng-r}) 
    & $L, L_{\min}, \nu $ {\sf isUpdateInTheLoop}\\
    \hline
    \sf EG-VI-UPK
    & Algorithm~\ref{Algo:ExtraGradient-vi} with the formulation (\ref{eq:vi-I}) and Algorithm~\ref{Algo:Up1} with (\ref{eq:Khobotov-r})
    &  $L, L_{\min}, \nu $ {\sf isUpdateInTheLoop}\\
    \hline
    \sf EG-VI-UPTS
    & Algorithm~\ref{Algo:ExtraGradient-vi} with the formulation (\ref{eq:vi-I}) and Algorithm~\ref{Algo:Up1} with (\ref{eq:SolodovTseng-r})
    & $L, L_{\min}, \nu $ {\sf isUpdateInTheLoop}\\
    \hline
    \sf HPA-VI-1 
    & Algorithm~\ref{Algo:HPA} with the formulation (\ref{eq:vi-I})
    & $\sigma,\tau$\\
    \hline
    \sf HPA-VI-2 
    & Algorithm~\ref{Algo:HPA} with the formulation (\ref{eq:vi-II})
    & $\sigma,\tau$\\ 
    \hline
  \end{tabular}
  \caption{Naming convention for the algorithms based on VI formulations.}
  \label{tab:Projection-algos}
\end{table}


\begin{ndrva}
  \begin{itemize}
  \item Situate the work of \cite{DeSaxce.Feng90,DeSaxce.Feng1998} and  \cite{Simo.Laursen1992,Laursen.Simo1993b}.
  \item Cite somewhere \citep{Laborde.Renard_MMAS2008}
  \item Have a careful look to the work of Krause.
  \item Implement the work of Simo just to laugh
  \item Implement the FP-QVI-MJ and FP-QVI-AC within the De Saxce approach ?
  \item Rule and efficient Choice of $\rho$.
  \item Should we leave hyperplane projection ?
  \item Acceleration techniques and Nesterov Method ? FISTA and Nesterov work. INPPA 
  \item To be classified \cite{Yan.ea_CMA2008,Han.Lo_CMA2002,Han.Sun_CMA2004,Han_AMC2006,Yan.ea_AMC2009}
  \item Implement ~\citep{He.Liao_JOTA2002} prediction-correction method ?
  \end{itemize}
\end{ndrva}




\subsection{Splitting techniques and proximal point algorithm}

Splitting techniques are standard techniques to solve $\mathrm{VI}(F,X)$ when the function $F$ is affine, that is $F=Mz+q$. Usually, a block splitting of the matrix $M$ is performed and a Projected Successive Over Relaxation(PSOR) is used to solve the VI. Due to the particular structure of the cone $K$, that can be considered is a splitting contact by contact or by group of several contacts. The sub-problems that are generated can be then solved by a dedicated method for the VI that have been presented in the previous sections. In the same way, the proximal point algorithm can also be used which amounts to solving the original VI $\mathrm{VI}(F,X)$ by solving a sequence of $\mathrm{VI}(F_{c,x_k},X)$  problems such that $  F_{c,x}(z) = z - x + c F(z) , \quad c > 0$ and $\lim_ {k \rightarrow +\infty } \|x_k-z\| =0$.
This intermediate VI can be solved with any solvers presented in the previous sections. 

 Rather than entering into deeper details, we prefer to refer to Sect~\ref{Sec:SplittingTechniquesAndProx} for a more general family of solvers based on splitting techniques and proximal point algorithms 


 \begin{ndrva}
   What can be retained from\cite{Heyn_PhD2013} ? Krylov techniques
 \end{ndrva}


\clearpage
\section{Newton based methods}
\label{sec:newtonmethods}

\begin{itemize}
\item Alart Curnier~\cite{Alart.Curnier1991}
\item Situate \cite{Simo.Laursen1992} w.r.t. Newton methods
\item Christensen et al.\cite{Christensen.Klarbring.ea1998}~\cite{Christensen.Pang1998},
\item Newton sur De Saxce cf P. Joly~\cite{Joli.Feng2008} . Equivalence natural map.
\item and others ?~\cite{Stadler_SIOPT2004}~\cite{Hueber.ea_SJSC2008,Hueber.Wolhmuth_CMAME2005}\cite{Koziara.Bicanic_CMAME2008}\cite{Renard_CMAME2013}
\item Update the section with the substitution of $u$
\end{itemize}

\subsection{Principle of the nonsmooth Newton methods}

In Section~\ref{Sec:NonsmoothEquations}, several formulations of the frictional contact problems by means of nonsmooth equations  have been presented. These nonsmooth equations call for the use of nonsmooth Newton's methods. If we consider the general equation~(\ref{eq:ne-1}) with $z = [u,v,r]^T$ we get
\begin{equation}
  \label{eq:NSN1}
  G(z)=0
\end{equation}
which can be solved by the following newton iteration
\begin{equation}
  \label{eq:NSN2}
  z_{k+1}  =  z_k -  J^{-1}(z_k) (G(z_k)).
\end{equation}
If the mapping $G$ is smooth enough, the matrix $J$ is the Jacobian matrix of $G$ with respect to $z$, that is $J(z) = \nabla^T_z G(z)$. When the $G$ is nonsmooth but Lipschitz,  the choice of a substitute to the Jacobian matrix can be given by an element of the Clarke sub--differential at $z$ denoted by $ \Phi(z) \in \partial G(z)$. Let us assume for a moment that the $\Phi$ is nonsingular, a nonsmooth Newton method can be written as 
\begin{equation}
  \label{eq:NSN3}
  z_{k+1}  =  z_k -  \Phi^{-1}(z_k) (G(z_k)).
\end{equation}
The resulting nonsmooth Newton method is detailed in Algorithm~\ref{Algo:NSN}.
\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf G $ Data of Problem~(\ref{eq:NSN1})
      \REQUIRE $\sf D$ a symmetric positive definite matrix
      \REQUIRE $\sf z_0$ initial values and $\sf tol >0$ a tolerance
      \ENSURE  $\sf z$ solution of Problem~(\ref{eq:NSN1})
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE compute (choose) $\sf \Phi(z_k) \in \partial G(z_k)$
      \STATE $\sf z_{k+1} \leftarrow   z_k -  \Phi^{-1}(z_k) (G(z_k))$
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$
      \ENDWHILE
      \STATE $\sf z \leftarrow z_{k}$ 
    }
  \end{algorithmic}
  \caption{Nonsmooth Newton method for (\ref{eq:NSN1})}  \label{Algo:NSN}
\end{algorithm}

\begin{ndrva}
  General results of local convergence ? --> give only citation.
\end{ndrva}
\subsection{Application to  the discrete frictional contact problem}

\subsubsection{Nonsmooth newton based on the natural map }
Let us consider the natural map $F_{\vitwo}^\nat$ in~(\ref{eq:natural-II}) that enables to write Problem~\ref{prob:II} in a nonsmooth equation. Algorithm~\ref{Algo:NSN} is applied or $z =r$ with
\begin{equation}
  \label{eq:phiphi}
  \begin{cases}
    \Phi(r) \in \partial_{r} F_{\vitwo}^\nat(r)
  \end{cases}
\end{equation}
 The details of a possible computation of $\Phi$ can be found in Appendix~\ref{Sec:Phi-natural-typeII}.  Similar computations can also be found in~\cite{Joli.Feng2008} where a Newton method based on the formulation~(\ref{eq:natural-II}) is used contact by contact in a Gauss--Seidel loop.

Let us consider the natural map $F_{\vione}^\nat$ in~(\ref{eq:natural-I}) that enables to write Problem~\ref{prob:I} in a nonsmooth equation.  Algorithm~\ref{Algo:NSN} may be also applied or $z =(v,r)$ with
\begin{equation}
  \label{eq:phiphi}
  \begin{cases}
    \Phi(v,r) \in \partial_{v,r} F_{\vione}^\nat(r)
  \end{cases}
\end{equation}

\begin{ndrva}
  \begin{itemize}
    \item  Idea : Iteration can also be interesting to state a Newton method
    on the normal map since the evaluation of $F$ is only made on $K$
    and not outside. Perhaps, we can control the regularity of the
    subgradients of $F(P_X(z))$
    \item In \cite{Hayashi.ea_SIOPT2005}, spectral decomposition of the projection + smoothing.  semi-smooth Newton method
  \end{itemize}
\end{ndrva}

\subsubsection{Newton method based on Alart--Curnier function and its variants}
\label{Sec:NSN-AC}
Let us consider now the Alart--Curnier function $F_{\actwo}(u,r)$ in~(\ref{eq:AC-II}) for Problem~\ref{prob:II}.
\begin{equation}
  \label{eq:phiphi-AC}
  % \begin{cases}
  %   \Phi(r) \in \partial_{r} F_{\actwo}^\nat(r) = \rho W \partial_{x}  \left[ \begin{array}{c}
  %       r_\n - P_{\RR^{n_c}_+}(r_\n - \rho_\n (W r +  q)_\n) \\
  %       r_\t - P_{D(\mu, (r_\n - \rho_\n u_\n)_+)}(r_\t - \rho_\n (W r +  q)_\t   )
  %     \end{array}\right]
  %   \begin{bmatrix}
  %   \end{bmatrix}
  % \end{cases}
   \ldots
\end{equation}
The details of a possible computation of $\Phi$ can be found in Appendix~\ref{Sec:Phi-AC-II}

\begin{ndrva}
  choice of $\rho_\n$ $\rho_\t$
\end{ndrva}



\subsubsection{Newton method based on  SOCC-function}
\label{Sec:Num-SOCCP}


\begin{ndrva}
  This is perhaps  too much
\end{ndrva}


\begin{ndrva}
  Is the proj formulation better than FB for all the reason related to the augmented Lagrangian approach
  See \cite{Mirar.Arora_SMO2004-I} for an automatic adaption of the penalization coefficient ? Link woth the work of Armand
\end{ndrva}



\paragraph{smoothing}
and its smoothed version with a regularization parameter $\tau>0$ as
\begin{equation}
  \label{eq:Jordan-FB-smoothed}
  \phi_{\fb, \tau}(x,y) = x+y - (x^2 + y^2 + 2 \tau^2 e)^{1/2}
\end{equation}
where $e = (1,0,0)$ is the identity element of the Jordan algebra, that is $e \cdot x =x$. In the same vein, the class of smoothing function of the natural map for NCP developed in~\cite{Chen.Mangasarian1996} is extended to SOCCP in~\cite{Fukushima.ea2001}.



\cite{Fukushima.ea2001}
\cite{Zhang.ea2009}
\cite{Hayashi.ea_SIOPT2005}




\begin{ndrva}
  TBW
\end{ndrva}



\subsection{Damped Newton and Line-search procedures}

\begin{itemize}
\item   (GP, Armijo, FBLSA, Non-monotone watch dogs)
\end{itemize}


\subsection{Nomenclature}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|l|p{0.6\textwidth}|l|}
    \hline
    { Algorithm}
    & Description 
    & parameters\\
    % \hline
    % \sf NSN-NA-1
    % &  Algorithm~\ref{Algo:NSN} with natural map for Problem~\ref{prob:I}
    % & \\
    \hline
    \sf NSN-NM 
    &  Algorithm~\ref{Algo:NSN} with the natural map formulation~(\ref{eq:natural-II})
    &  $tol, \rho$\\
    \hline
    % \sf NSN-AC-1 
    % &  Algorithm~\ref{Algo:NSN} with Alart-Curnier formulation for Problem~\ref{prob:I}  
    % & \\
    % \hline
    \sf NSN-AC
    &  Algorithm~\ref{Algo:NSN} with the Alart--Curnier formulation~(\ref{eq:AC-II})
    &  $tol, \rho_\n, \rho_\t$\\
    \hline
    % \sf NSN-JM-1 
    % &  Algorithm~\ref{Algo:NSN} with Jean--Moreau formulation for Problem~\ref{prob:I}
    % & \\
    % \hline
    \sf NSN-JM 
    &  Algorithm~\ref{Algo:NSN} with the Jean--Moreau formulation~(\ref{eq:MJ-II})
    & $tol, \rho_\n, \rho_\t$\\
    \hline
    \sf NSN-FB 
    &  Algorithm~\ref{Algo:NSN} with the Fischer-Burmeister formulation~(\ref{eq:FB-II})
    & $tol$\\
    \hline
    \sf NSN-MJ-GP
    &  ??
    & \\
    \hline
    \sf NSN-AC-GP
    &  Algorithm~\ref{Algo:NSN} with the Alart--Curnier formulation~(\ref{eq:AC-II}) and the Goldstein--Price (GP) line search
    & \\
    \hline
    \sf NSN-AC-FBLSA
    &  Algorithm~\ref{Algo:NSN} with the Alart--Curnier formulation~(\ref{eq:AC-II}) and the FBLSA line search
    & \\
    \hline
    \sf NSN-FB-GP 
    &  Algorithm~\ref{Algo:NSN} with the Fischer-Burmeister formulation~(\ref{eq:FB-II}) and the Goldstein--Price (GP) line search
    & \\
    \hline
    \sf NSN-FB-FBLSA
    &  Algorithm~\ref{Algo:NSN} with the Fischer-Burmeister formulation~(\ref{eq:FB-II}) and the  FBLSA line search
    & \\
    \hline
    \sf \ldots 
    &  \ldots
    & \\
    \hline
  \end{tabular}
  \caption{Naming convention for the algorithms based on nonsmooth Newton (NSN) method}
  \label{tab:NSN-algos}
\end{table}

\clearpage
\section{Splitting techniques and proximal point algorithm}
\label{Sec:SplittingTechniquesAndProx}

\subsection{Splitting techniques}
\label{Sec:SplittingTechniques}
 The particular structure of the cone $K$ as a product of second-order cone in $\RR^3$ suggests a special splitting of the problem for each contact labelled by $\alpha \in 1\ldots n_c$. 

For Problem~\ref{prob:II}, the relation
\begin{equation}
  \label{eq:delassus-bis}
  u = W r+q
\end{equation}
is split along each contact as follows
\begin{equation}
  \label{eq:delassus-ter}
  u^\alpha = W^{\alpha\alpha} r^\alpha + \sum_{\beta\neq \alpha}W^{\alpha\beta} r^\beta +  q^\alpha, \text{ for all } \alpha \in 1\ldots n_c,
\end{equation}
where the matrices $W^{\alpha\beta}, \alpha \in 1\ldots n_c, \beta \in 1\ldots n_c $ are easily identified from~(\ref{eq:delassus-bis}).
 
From~(\ref{eq:delassus-ter}), a projected Gauss--Seidel (PGS) method can be designed by using the following rule at the iterate $k$
\begin{equation}
  \label{eq:pgs-1}
  u^{\alpha}_{k+1} = W^{\alpha\alpha} r^{\alpha}_{k+1} + \sum_{\beta < \alpha}W^{\alpha\beta} r^{\beta}_{k+1} + \sum_{\beta > \alpha}W^{\alpha\beta} r^{\beta}_{k} +  q^\alpha, \text{ for all } \alpha \in 1\ldots n_c,
\end{equation}
and more generally a Projected Successive Over Relaxation(PSOR) is obtained by introducing a relaxation parameter $\omega>0$ such that
\begin{equation}
  \label{eq:psor-1}
  u^{\alpha}_{k+1} = \frac 1 \omega W^{\alpha\alpha} r^{\alpha}_{k+1} 
  - \frac 1 \omega W^{\alpha\alpha} r^{\alpha}_{k} +
  \sum_{\beta < \alpha}W^{\alpha\beta} r^{\beta}_{k+1} + \sum_{\beta \geq \alpha}W^{\alpha\beta} r^{\beta}_{k} +  q^\alpha, \text{ for all } \alpha \in 1\ldots n_c.
\end{equation}
By denoting 
\begin{equation}
  \label{eq:psor-2}
  \begin{cases}
    \Bar W^{\alpha\alpha} = \frac 1 \omega W^{\alpha\alpha} \\
    \bar q^{\alpha}_{k+1} = - \frac 1 \omega W^{\alpha\alpha} r^{\alpha}_{k}
    + \sum_{\beta < \alpha}W^{\alpha\beta} r^{\beta}_{k+1} + \sum_{\beta
      \geq \alpha}W^{\alpha\beta} r^{\beta}_{k} + q^\alpha
  \end{cases}
, \text{ for all } \alpha \in 1\ldots n_c,
\end{equation}
we have to solve at each iteration the following problem on each contact $\alpha$
\begin{equation}\label{eq:psor-3}
  \begin{cases}
    u^{\alpha}_{k+1} =  \Bar W^{\alpha\alpha}  r^{\alpha}_{k+1} + \bar q^{\alpha}_{k+1}, \\
    \hat u^{\alpha}_{k+1} =u^{\alpha}_{k+1} + g(u^{\alpha}_{k+1}), \\[2mm]
    K^{\alpha,\star} \ni {\hat u^{\alpha}_{k+1}} \perp r^{\alpha}_{k+1} \in K^\alpha.
  \end{cases}
\end{equation}
The problem on each contact~(\ref{eq:psor-3}) has exactly the same structure as Problem~\ref{prob:II}, but only concerns one contact. It can be solved analytically of by invoking one of the algorithms presented in this paper a local solver for the sub-problems. The PSOR algorithm is summarized in Algorithm~\ref{Algo:PSOR-II}.

\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $ 
      \REQUIRE $\sf W,q,\mu $ Date of Problem~\ref{prob:II} 
      \REQUIRE $\sf r_0$ initial values and $\sf tol >0$ a tolerance
      \REQUIRE $\sf \omega$ a relaxation parameter 
      \ENSURE  $\sf r,u$ solution of Problem~\ref{prob:II}
      \WHILE {$\sf error > tol$} 
      \FOR {$\sf \alpha = 1 \ldots n_c$}
      \STATE $\sf \bar W^{\alpha\alpha}_{k+1} \leftarrow  \frac 1 \omega W^{\alpha\alpha}$
      \STATE $\sf   \bar q^{\alpha}_{k+1} \leftarrow - \frac 1 \omega W^{\alpha\alpha} r^{\alpha}_{k}
      + \sum_{\beta < \alpha}W^{\alpha\beta} r^{\beta}_{k+1} + \sum_{\beta
        \geq \alpha}W^{\alpha\beta} r^{\beta}_{k} + q^\alpha $
      \STATE Solve the single contact problem $\sf \mathrm{FC/II}(\bar W^{\alpha\alpha},\bar q^{\alpha}_{k+1},\mu)$
      \ENDFOR
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$ 
      \ENDWHILE
      \STATE $\sf r \leftarrow r_{k}$ 
      \STATE $\sf u \leftarrow u_{k}$ 
    }
  \end{algorithmic}
  \caption{PSOR algorithm for Problem~\ref{prob:II}}  \label{Algo:PSOR-II}
\end{algorithm}

In~\cite{Jourdan.Alart.ea98}, this method is developed in the Gauss-Seidel configuration ($\omega=1$) with a local Newton solver based on the Alart--Curnier formulation. If the local solver is only one iteration of the VI solver based on projection, we get a standard splitting techniques for VI. In Table~\ref{tab:PSOR-algos}, the methods based on PSOR used in the comparison are summarized.

\begin{ndrva}
  \begin{itemize}
  \item Situate \cite{Hayashi.ea_JCAM2005}
  \item Do not forget the overrelaxation and some heuristic to adapt convergence (line search).
  \item Accelration technique
    Aitken acceleration. Lebon, Raous et al.
    
    Problem~\ref{prob:I} ??
    
    contractive sequence transformations in 
    
    C. Brezinski et M. Redivo-Zaglia, Extrapolation Methods, Theory and Practise, North- Holland, Amsterdam, 1992.
    
    J.P. Delahaye, Sequence transformations, Springer Verlag, Berlin, 1988.
  \end{itemize}
\end{ndrva}




\subsection{Proximal points techniques}

\begin{ndrva}
  Small introduction on proximal functions of Moreau, algo of Martinet
  and result of Rockafellar (see \cite{Chen.Teboublle_SIOPT1993})
\end{ndrva}

Without entering into theoretical aspects, the key idea of proximal points algorithms it to replace the original $\mathrm{VI}(F,X)$ by a sequence of $\mathrm{VI}(F_{\rho,x_k},X)$  problems such that 
\begin{equation}
  \label{eq:prox-algo-1}
  F_{\rho,x}(z) = z - x_k+ \alpha F(z) , \quad \rho > 0 
\end{equation}
with the property that $\lim_{ k \rightarrow +\infty} \| x_k -z \| = 0$. This is usually performed by defining a sequence $x_k$ such that
\begin{equation}
  \label{eq:prox-algo-2}
  x_{k+1} = (1-\omega) x_{k} + \omega z_{k+1}
\end{equation}
where $\omega$ is a relaxation parameter and $z_{k+1}$ the solution of $\mathrm{VI}(F_{\rho,x_k},X)$. The algorithm is described in algorithm~\ref{Algo:PPA-vi}
\begin{algorithm}
  \begin{algorithmic}
    {\sf
      \STATE $ $
      \REQUIRE $\sf F,X$ Data of VI~(\ref{eq:vi})
      \REQUIRE $\sf \omega$ relaxation parameter
      \REQUIRE $\sf \alpha$ proximal point parameter
      \REQUIRE $\sf x_0$ initial values
      \REQUIRE $\sf tol >0, tol_{in}$ tolerances
      \ENSURE  $\sf z$ solution of VI~(\ref{eq:vi})
      \STATE   $\sf k \leftarrow 0$ 
      \WHILE {$\sf error > tol$} 
      \STATE Solve $\mathrm{VI}(F_{\alpha,x_k},X)$ for $\sf z_{k+1}$ with tolerance $\sf tol_{in}$
      \STATE $\sf x_{k+1} \leftarrow (1-\omega) x_{k} + \omega z_{k+1}$
      \STATE Evaluate $\sf error$.
      \STATE $\sf k \leftarrow k+1$
      \ENDWHILE
      \STATE $\sf z \leftarrow z_{k+1}$ 
    }
  \end{algorithmic}
  \caption{Proximal point algorithm for the VI~(\ref{eq:vi})}  \label{Algo:PPA-vi}
\end{algorithm}

For solving the sub-problem $\mathrm{VI}(F_{\alpha,x_k},X)$, any of the previous presented algorithms can be used. In this sense, the proximal point algorithm defined a general family of algorithm. The main interest of the proximal point algorithm is the regularization it introduces in the  definition (\ref{eq:prox-algo-1}). For instance, let consider an affine VI, that is defined with $F(z)=M z+q$. The function is the sub-problem is given by
\begin{equation}
  \label{eq:prox-algo-4}
   F_{\alpha,x}(z) = (I + \alpha M) z - x_k + \rho q , \quad \rho > 0 .
\end{equation}
We can easily that for sufficiently small $\rho$, we get a monotone affine VI and even better an strongly monotone VI. For Problem~\ref{prob:II} with $F_{\vitwo}$, the proximal point algorithm yields
\begin{equation}
  \label{eq:prox-algo-5}
   F_{\vitwo,\rho,x}(r) = (I + \alpha W) r - x_k + \alpha( q + g(W r +q )) , \quad \rho > 0 .
\end{equation}
and it should not be difficult to prove that with a small $\rho$ parameter that we get a monotone VI.  Naturally, there is a price to pay, smaller the parameter $\rho$ is, easier the VI problem is, but the resulting solution of $z_{k+1}$ is far from the solution.

The use of proximal point algorithm can be very interesting when the solving of the problem suffers for the lack of regularity of the operator. For instance, the Newton methods are in trouble when the Jacobian is not invertible. Thanks to the proximal point algorithm, we can retrieve invertible Jacobian.


\begin{ndrva}
  \begin{itemize}
  \item Prove it !
  \item Is there a analogy with choosing a small $r$ ?
  \item Techniques of \citep{Han_JCAM2008} for sizing alpha
  \end{itemize}
\end{ndrva}

\subsection{Naming convention}
\begin{table}
  \centering
  \begin{tabular}{|l|p{0.6\textwidth}|l|}
    \hline
    { Algorithm}
    & Description 
    & parameters\\
    \hline
    \sf NSGS-AC
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with the local solver NSN-AC with tolerance $tol_{local}$
    & $tol, tol_{local},  \rho_\n, \rho_\t$\\
    \hline
    \sf NSGS-JM
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with the local solver NSN-JM with tolerance $tol_{local}$
    & $tol, tol_{local}, \rho_\n, \rho_\t$\\
    \hline
    \sf NSGS-AC-GP
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with the local solver NSN-AC-GP with tolerance $tol_{local}$
    & $tol, tol_{local}, \rho_\n, \rho_\t$\\
    \hline
    \sf NSGS-JM-GP
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with the local solver NSN-JM=GP with tolerance $tol_{local}$
    & $tol, tol_{local}, \rho_\n, \rho_\t$\\
    \hline
    \sf NSGS-FP-DS-One
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with one iteration of FP-DS for the local solver
    & $tol$\\
    \hline
    \sf NSGS-FP-VI-UPK
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with FP-VI-UPK for the local solver with tolerance $tol_{local}$
    & $tol, tol_{local}, $\\
    \hline
    \sf NSGS-EXACT
    & Algorithm~\ref{Algo:PSOR-II} with $\omega=1$ with the exact local solver.
    & $tol$\\
    \hline
    \hline
    \sf PSOR-AC 
    &  Algorithm~\ref{Algo:PSOR-II} with  with the local solver NSN-AC with tolerance $tol_{local}$
    & $\omega, tol,  tol_{local}$\\
    \hline
    \hline
    \sf PPA-NSN-AC 
    &  Algorithm~\ref{Algo:PPA-vi} with the NSN-AC solver as internal solver.
    & $\omega,\rho$\\
    \hline
    \sf PPA-NSGS-AC
    &  Algorithm~\ref{Algo:PPA-vi} with the NSGS-AC solver as internal solver.
    & $\omega,\rho$\\
    \hline
  \end{tabular}
  \caption{Naming convention for the algorithms based on splitting and proximal algorithms}
  \label{tab:PSOR-PPA-algos}
\end{table}

\begin{ndrva}
  add std choice for $\rho_\n,\rho_\t$
\end{ndrva}
\clearpage
\section{Interior point methods for SOCCP}
\label{Sec:InteriorPoint}

\cite{Kleinert.ea_CMAME2014} and references therein

\cite{Christensen.Pang1998}


\cite{Heyn.ea_IJNME2013} + PhD thesis \cite{Heyn_PhD2013}

Frictionless ? :\cite{Miyamura.ea_IJNME2010,Temizer.ea_CMAME2014}
 

\section{Optimization based methods}
\label{Sec:OptimisationBasedMethods}

\subsection{Alternating optimization problem}
Panagiotopoulos. Un coup N un coup T

\subsection{Successive approximation  method}

methods of successive approximation successive approximations is a natural tool for the numerical realization [3]. Each iterative step is represented by an auxiliary contact problem with given friction described by a variational inequality of the second kind.


\cite{Haslinger.ea_CMAME2002} \& \cite{Dostal_JCAM2002} : successive approximation in 2D a) classical Tresca iteration (FPMI).  b) splitting N/T plus a Fixed point (FPMII). Use of a specific QP solver for box constraint~\cite{Dostal_SIOPT1997} that is a improvement of MOre Toraldo method.

\cite{Haslinger.ea_JCAM2004}.  Extension to 3D with faceting the cone. The QP is box constrained QP.


\cite{Haslinger.ea_MCS2012}  successive approximation in 3D the special solver of \cite{Kucera_OMS2007,Kucera_SIOPT2008} which is itself and extension to disk constraints of the Polyak method (CG +active set on bounds constraint) and its improvements~\cite{Dostal_SIOPT1997,Dostal.Schoberl_COA2005}.



\cite{Dostal.Kozubek_MP2012} An algorithm (extension of MPGP) for solving QP over convex constraint (disk constraint for instance). Application to frictional contact. 


\cite{Dostal.Kucera_SIOPT2010} last improvement of the method in \cite{Dostal.Kozubek_MP2012} and \cite{Kucera_SIOPT2008}




\subsection{ACLM approach}

\subsection{SOCCP approach}


\subsection{Naming convention}

\begin{table}
  \centering
  \begin{tabular}{|l|p{0.6\textwidth}|l|}
    \hline
    { Algorithm}
    & Description 
    & parameters\\
    \hline
    \sf TRESCA-NSGS-FP-VI
    & 
    & $tol, tol_{local}$\\
    \hline
    \sf ACLM-NSGS-FP-VI
    & 
    & $tol, tol_{local}$\\
    \hline
    \hline
  \end{tabular}
  \caption{Naming convention for the algorithms based on splitting and proximal algorithms}
  \label{tab:PSOR-PPA-algos}
\end{table}


\section{Comparison framework}
\label{sec:numericalcomparisons}
\subsection{Measuring errors}
\label{Sec:MeasuringErrors}

\subsection{Parameters}

\begin{itemize}
\item size (n, m), sparsity,
\item matrix storage
\item conditionning $M$ $W$
\item rank of $H$ or $W$ on active contact
\item parameter $\nu = m_c/n$
\end{itemize}

\begin{itemize}
\item algorithms parameters ($\rho$)
\end{itemize}


\subsection{Measure of performance}
\begin{itemize}
\item CPU time and memory or better flops (papi) for a fixed user tolerance
\item Reached accuracy for a given CPU effort
\end{itemize}
Other studies.
\begin{itemize}
\item Convergence rate (error w.r.t. flop within the iteration process)
\item Scalable properties () study with a set of large size ?
\end{itemize}

\subsection{Benchmarks presentation}

\subsection{Sofware \& implementation details}
\clearpage


\section{Comparison of methods by family}

\subsection{Numerical methods for VI}


\def\widthfigure{0.6}
\paragraph{Evaluation of the influence of the self--adaptive procedure for step length}
\label{Sec:Comparison,VI,step-length}

\begin{figure}
  \centering
  \vspace{-0.5cm}
  \subfigure[Capsules tests (reduced) $tol = 10^{-8},timeout=10s$]{\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-Capsules.pdf}\hspace{-3cm}\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-Capsules_legend.pdf}} \vspace{-0.5cm}
  \subfigure[KaplasTower $tol = 10^{-8}, timeout=50s$]{\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-KaplasTower.pdf}\hspace{-3cm}\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-KaplasTower_legend.pdf}}\vspace{-0.5cm}
  \subfigure[LMGC\_Bridge\_PR $tol = 10^{-5}, timeout=50s$]{\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-LMGC_Bridge_PR.pdf}\hspace{-3cm}\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-LMGC_Bridge_PR_legend.pdf}}\vspace{-0.5cm}
  \subfigure[LMGC\_Cubes\_H8\_20 $tol = 10^{-5}, timeout=50s$]{\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-LMGC_Cubes_H8_20.pdf}\hspace{-3cm}\includegraphics[width=\widthfigure\textwidth]{../figure/VI/UpdateRule/time/profile-LMGC_Cubes_H8_20_legend.pdf}}
  \caption{Evaluation of the influence of the self--adaptive procedure for step length.}
  \label{fig:VI/UpdateRule/time/profile-Capsules}
\end{figure}
In Figure~\ref{fig:VI/UpdateRule/time/profile-Capsules}, we study the effect of the self--adaptive procedure in Algorithm~\ref{Algo:Up1} on the convergence of the of the fixed point method in Algorithm~\ref{Algo:FP-vi}.


\paragraph{Comparison between fixed point, extragradient and projection--contraction method.}



\subsection{Splitting based algorithms}

\begin{ndrva}
TODO list
\begin{itemize}
\item Effect and influence of the local solver
\item Influence of the tolerance of the local solver $tol_{local}$
\item Influence of the contacts order
\item Comparison of PSOR algorithm with respect to the relaxation parameter $\omega$
\end{itemize}
\end{ndrva}

\paragraph{Effect and influence of the local solver in NSGS algorithms}




\def\widthfigure{0.6}
\begin{figure}
  \centering
  \vspace{-1cm}
  \subfigure[Capsules tests (reduced) $tol = 10^{-8},timeout=10s$]{\label{fig:NSGS/LocalSolver/time/profile-Capsules}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-Capsules.pdf}
    \hspace{-2cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-Capsules_legend.pdf}}\vspace{-0.5cm}
  \subfigure[KaplasTower $tol = 10^{-8}, timeout=50s$]{\label{fig:NSGS/LocalSolver/time/profile-KaplasTower}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-KaplasTower.pdf}
    \hspace{-2cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-KaplasTower_legend.pdf}}\vspace{-0.5cm}
  \subfigure[LMGC\_Bridge\_PR $tol = 10^{-5}, timeout=50s$]{\label{fig:NSGS/LocalSolver/time/profile-LMGC_Bridge_PR}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-LMGC_Bridge_PR.pdf}
    \hspace{-2cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-LMGC_Bridge_PR_legend.pdf}}\vspace{-0.5cm}
  \subfigure[LMGC\_Cubes\_H20 tests. $tol = 10^{-4},timeout=50s$]{\label{fig:NSGS/LocalSolver/time/profile-Cubes_H8_20}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-Cubes_H8_20.pdf}
    \hspace{-2cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalSolver/time/profile-Cubes_H8_20_legend.pdf}}\vspace{-0.5cm}
  \caption{Influence of the local solver in NSGS algorithms.}
  \label{fig:NSGS/LocalSolver/time}
\end{figure}

\paragraph{Influence of the tolerance of the local solver $tol_{local}$ in NSGS algorithms}

\begin{figure}
  \centering\vspace{-0.5cm}
  \subfigure[Capsules tests (reduced) $tol = 10^{-8},timeout=10s$]{\label{fig:NSGS/LocalTol/time/profile-Capsules}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-Capsules.pdf}
     \hspace{-1cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-Capsules_legend.pdf}}\vspace{-0.5cm}
  \subfigure[KaplasTower $tol = 10^{-8}, timeout=50s$]{\label{fig:NSGS/LocalTol/time/profile-KaplasTower}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-KaplasTower.pdf}
     \hspace{-1cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-KaplasTower_legend.pdf}}\vspace{-0.5cm}
  \subfigure[LMGC\_Bridge\_PR $tol = 10^{-5}, timeout=50s$]{ \label{fig:NSGS/LocalTol/time/profile-LMGC_Bridge_PR}  \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-LMGC_Bridge_PR.pdf}
   \hspace{-1cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-LMGC_Bridge_PR_legend.pdf}}\vspace{-0.5cm}
  \subfigure[LMGC\_Cubes\_H20 tests. $tol = 10^{-4},timeout=50s$]{  \label{fig:NSGS/LocalTol/time/profile-Cubes_H8_20}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-LMGC_Cubes_H8_20.pdf}
     \hspace{-1cm}\includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/LocalTol/time/profile-LMGC_Cubes_H8_20_legend.pdf}}
  \caption{Influence of the tolerance of the local solver $tol_{local}$ in NSGS algorithms.} 
\end{figure}



\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Test set & required accuracy &  average performance \\
    \hline
    \hline
    Capsules & $10^{-08}$ & $ 1.072 \cdot 10^{-03} s$ \\
    KaplasTower & $10^{-08}$ &  $1.024 \cdot 10^{-03} s$ \\
    LMGC\_Bridge\_PR & $10^{-05}$&$1.581 \cdot 10^{-02} s $ \\
    LMGC\_Cubes\_H20 &$10^{-04}$ &$6.271 \cdot 10^{-02} s $\\
    \hline
  \end{tabular}
  \caption{The average performance of resolution by contacts for the best solver to reach a given accuracy.}
  \label{tab:hardness}
\end{table}



In this section, the tolerance of the local solver is varied and its effect on the global convergence of the solver is reported. For the ``Capsules'' set of examples in figure~\ref{fig:NSGS/LocalTol/time/profile-Capsules}, the tolerance of the local solver $tol_{local}$ has almost no effect on the performance of the global solver. Surprisingly, the algorithm is also able to reach the global accuracy of $tol = 10^{-8}$ with a quite low accuracy of the local solver ($10^{02}$ for instance). This mainly due to the fact that at least one iteration of the local solver is always done and the set of examples are not so difficult to solve (see the average performance in Table~\ref{tab:hardness}).
Let us have a look to more difficult examples in Figures~\ref{fig:NSGS/LocalTol/time/profile-LMGC_Bridge_PR} and  \ref{fig:NSGS/LocalTol/time/profile-Cubes_H8_20}. Although the required accuracy is lower, the solver with a low local tolerance fails to solve the problems efficiently. In the most difficult test set, it is even required to have a local tolerance $tol_{local}$ at a very low level with respect to the tolerance $tol$ to improve the rate of convergence and even to ensure the success of the solver.

\begin{ndrva}
  \item redo this comparison with the flop measure.
  \item The Capsules test seems very easy to solve
\end{ndrva}

\paragraph{Influence of the contacts order  in NSGS algorithms}

In this section, we study thein the list of contact that is iterated by the NSGS-AC solver. We reproduce in Figure~\ref{fig:NSGS/Shuffled/time/profile-Capsules} the result of the solvers with the original contact list of the problem (NSGS-AC), with the 10 lists of contacts that are randomly shuffled (NSGS-AC-Shuffles-x) and with a list of contact that is shuffled in each loop ot the solver(NSGS-AC-Shuffled-full). We can observe that the contact order change slightly the behavior of the algorithm and most surprisingly the randomization in each loop of the NSGS algorithm deteriorates its convergence. In Figure~\ref{fig:NSGS/Shuffled/time/profile-KaplasTower}, we restrict our attention to three solvers without noting major difference with the respect of the result of each solvers. In Figure~\ref{fig:NSGS/Shuffled/time/profile-Cubes_H8_20}, the result change drastically with the Cubes\_H8\_20 examples. For each problem, the randomization  in each loop improves the performance by a factor between $20$ and $60$. Note the scale of the axis. In view of this result, the question of the contact order seems to be an important question for improving the performance of the NSGS solvers. It remains nevertheless an open question since it is difficult to guess a priori what the optimal order.


\def\widthfigure{0.6}
\begin{figure}
  \centering\vspace{-0.5cm}
  \subfigure[Capsules tests (reduced) $tol = 10^{-8},timeout=10s$]{%
    \label{fig:NSGS/Shuffled/time/profile-Capsules}%
    \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-Capsules.pdf}
   \hspace{-1cm} \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-Capsules_legend.pdf}
  }\vspace{-0.5cm}
  \subfigure[KaplasTower $tol = 10^{-8}, timeout=50s$]{%
    \label{fig:NSGS/Shuffled/time/profile-KaplasTower}%
    \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-KaplasTower.pdf}
   \hspace{-1cm} \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-KaplasTower_legend.pdf}
  }\vspace{-0.5cm}
  \subfigure[LMGC\_Bridge\_PR tests. $tol = 10^{-5},timeout=50s$]{%
    \label{fig:NSGS/Shuffled/time/profile-LMGC_Bridge_PR}%
    \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-LMGC_Bridge_PR.pdf}
   \hspace{-1cm} \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-LMGC_Bridge_PR_legend.pdf}
  }\vspace{-0.5cm}
  \subfigure[LMGC\_Cubes\_H20 tests. $tol = 10^{-4},timeout=50s$]{%
    \label{fig:NSGS/Shuffled/time/profile-Cubes_H8_20}%
    \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-Cubes_H8_20.pdf}
   \hspace{-1cm} \includegraphics[width=\widthfigure\textwidth]{../figure/NSGS/Shuffled/time/profile-Cubes_H8_20_legend.pdf}
  }
  \caption{Influence of the contacts order in NSGS algorithms.}
\end{figure}

\begin{ndrva}
  \item Not so great interest of this section because it is difficult to conclude something
\end{ndrva}

\paragraph{Comparison of PSOR algorithm with respect to  the relaxation parameter $\omega$}

\begin{figure}
  \centering
  \subfigure[Capsules tests (reduced) $tol = 10^{-8},timeout=100s$]{\includegraphics[width=\widthfigure\textwidth]{../figure/PSOR/flpops/profile-Capsules.pdf}\hspace{-3cm} 
    \includegraphics[width=\widthfigure\textwidth]{../figure/PSOR/flpops//profile-Capsules_legend.pdf}
  }
 \subfigure[KaplasTower $tol = 10^{-8}, timeout=100s$]{\includegraphics[width=\widthfigure\textwidth]{../figure/PSOR/flpops/profile-KaplasTower.pdf}\hspace{-3cm} 
    \includegraphics[width=\widthfigure\textwidth]{../figure/PSOR/flpops//profile-KaplasTower_legend.pdf}
  }
  \caption{Effect of relation coefficient $\omega$ in PSOR-AC algorithm($tol_{local} = 10^{-16}$).}
  \label{fig:PSOR/flpops}
\end{figure}

In Figure~\ref{fig:profile-Capsules-PSOR-1_15-time}, we study the effect of the relaxation parameter $\omega$ ranging from $[0.5,1.5]$ on the computational time.  Two conclusions can be drawn a) with increasing values of $\omega$, the PSOR algorithm increases its convergence rate as we van observe for $\tau=1$ but b) the robustness of the algorithm is weaken. Indeed, $\tau=15$, we observe that the performance profile is flat and the number of problems solved is higher for valued of $\omega$ around $1$.

To conclude, it is difficult to advice to use PSOR algorithm with $\omega\neq 1$. If it accelerates drastically the rate of convergence of the algorithm for some problems it deteriorates the convergence for other. Further studies would be needed to design self--adaptive schemes for the choice of $\omega$.

\begin{ndrva}
  \item redo this comparison on a set of mixed examples
  \item add some results with $\omega =1.8$ to show that higher values will destroy the convergence.
  \item is it possible to find sizing rule in the literature ?
\end{ndrva}



\subsection{Comparison of PPA-NSN-AC algorithm with respect to  the step-size parameter $\sigma$, $\mu$}

\begin{figure}
  \centering
  \subfigure{\includegraphics[width=\widthfigure\textwidth]{../figure/PROX/Parameters/flpops//profile-Capsules.pdf} \hspace{-3cm} 
    \includegraphics[width=\widthfigure\textwidth]{../figure/PROX/Parameters/flpops//profile-Capsules_legend.pdf}
  }
  \subfigure{\includegraphics[width=\widthfigure\textwidth]{../figure/PROX/Parameters/flpops/profile-KaplasTower.pdf} \hspace{-3cm} 
    \includegraphics[width=\widthfigure\textwidth]{../figure/PROX/Parameters/flpops//profile-KaplasTower_legend.pdf}
  }
  \caption{Effect of the step-size parameter $\sigma$, $\mu$ in PPA-NSN-AC algorithm}
  \label{fig:profile-Capsules-reduced-PPA-NSN-AC-1_10-time}
\end{figure}

\begin{ndrva}
  \item redo this comparison on a set of mixed examples 
  \item add some results with $\nu < 1 $
\end{ndrva}


\section{Comparison of different families of solvers.}


% \subsection{Rigid bodies applications}
% \begin{figure}
%   \centering
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Bridge_PR-time_0_100.pdf}
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Bridge_PR_legend-time_0_100.pdf}
%   \caption{Bridge\_PR tests. $timeout=50s, tol = 10^{[-4} $ performance (time). }
%   \label{fig:profile-LMGC_Bridge_PR-time}
% \end{figure}



% \subsection{Finite Element applications}

% \begin{figure}
%   \centering
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Cubes_H8_5-time_0_100.pdf}
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Cubes_H8_5-time_0_5000.pdf}
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Cubes_H8_5_legend-time.pdf}
%   \caption{Cubes H8\_5 tests. $timeout=50s $ performance (time). }
%   \label{fig:profile-LMGC_Cubes_H8_5-time}
% \end{figure}

% \begin{figure}
%   \centering
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Cubes_H8_20-time_0_100.pdf}
%   \includegraphics[width=\widthfigure\textwidth]{../figure/profile-LMGC_Cubes_H8_20_legend-time.pdf}
%   \caption{Cubes H8\_20 tests. $timeout=50s $ performance (time). }
%   \label{fig:profile-LMGC_Cubes_H8_20-time}
% \end{figure}


\subsection{CPU and memory efforts for a given tolerance}

Analyze the quickest one and the more robust one.

\subsection{Analyze reached accuracy for a given time}



\bibliographystyle{plainnat}
\bibliography{./biblio/String,./biblio/NonSmooth,./biblio/Math,./biblio/Multibody,./biblio/Fem.bib,./biblio/Dae.bib,./biblio/Meca,./biblio/AnaNum.bib,./biblio/Math-Impact,./biblio/Contact,./biblio/Optim,./biblio/Cp}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "rr"
%%% End: 
