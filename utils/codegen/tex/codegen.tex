\documentclass[a4paper]{article}

\usepackage{listing}
\usepackage{caption}
\usepackage{minted}
\usepackage{RR}
\usepackage{a4wide} 

\RRdate{\today}
\RRauthor{Maurice Br\'emond {\tt
    maurice.bremond@inria.fr}}
\authorhead{}
\RRtitle{A code generation
  procedure with verifications for the computation of generalized jacobians}
\RRetitle{}
\titlehead{}
\RRresume{}
\RRabstract{Given the expression of a nonsmooth
  function in Sympy, a Python computer algebra system, an element of its
  generalized jacobian may be expressed as a piecewise function. This
  piecewise function takes its values on the smooth domain, where it is the
  smooth jacobian computed by the computer algebra system, and on the
  nonsmooth domain where some values must be provided explicitely. With the
  help of a small tool a C code is generated from this piecewise function. If
  the expression of the generalized jacobian is correct, for inputs in a
  bounded domain, the computation of the jacobian must gives finites
  results. This may be proven with the help of added ACSL static assertions to
  give hints to the frama-c value analysis tools and its subsequents proofs
  obligations.}
\RRmotcle{}
\RRkeyword{}
\RRprojet{Bipop}
\URRhoneAlpes
\RCGrenoble

\PassOptionsToPackage{dvipsnames,svgnames}{xcolor}   
\renewcommand{\baselinestretch}{1.5}
\usepackage{natbib}

\input{packages.tex}
\input{macro.tex}

%%
\begin{document}
%%
\RRNo{123456789}
%\makeRR   % cas d'un rapport de recherche
\makeRT
%% a partir d'ici, chacun fait comme il le souhaite

\newpage
\tableofcontents
\newpage

\section{Introduction}
The computation of numerical solutions of miscellaneous nonsmooth physical
problems may need the expression and the computation of Clarke Generalized
gradients \cite{Clarke1975}.  Code writing for such jacobians can be tedious
and error prone. Errors in the computation may not be obvious to detect when
the jacobian is used in nonsmooth Newton method.


\section{The Method}


The method:

1. Express nonsmooth function in a computer algebra system (Maple, Sagemath, Sympy)

2. Compute the jacobian on differentiable points.

3. Express generalized jacobian as a piecewise function : continuous : ``normal jacobian'',  non differentiable point : a limit

4. perform common subexpression elimination up to functions sqrt, Abs, Max, Heaviside, etc.

5. produce c code with static assertions (value analysis fails without them)

6. static verification with frama-c:

output a proof of: limited domain (physically admissible domain) for inputs ==> is\_finite(result)

\section{Examples}

\subsection{Euclidian norm function}

\subsubsection{code generation from the mathematical definition}
\begin{equation}
  \begin{array}{ll}
  \left [\begin{array}{c}
    x\\
    y
    \end{array} \right] \mapsto \sqrt{x^2+y^2}
  \end{array}
\end{equation}

\begin{equation}
  \begin{array}{ll}
    \left [
      \begin{array}{c}
        x\\
        y
      \end{array} \right]
    \mapsto \left\{
        \begin{array}{ll}
          \left[
            \begin{array}{c}
            \frac{x}{\sqrt{x^2+y^2}}\\
            \frac{y}{\sqrt{x^2+y^2}}
          \end{array} \right] & \mbox{if } (x, y) \in \RR^{\star 2} \\
        \{ v \in \RR^2, ||v|| = 1 \} & \mbox{if } (x, y) = (0, 0)
        
      \end{array}
    \right.
  \end{array}
\end{equation}

\begin{listing}[H] 
  \begin{minted}[frame=single]{python}
    from sympy import Symbol, Matrix, sqrt
    x = Symbol('x', real=True)
    y = Symbol('y', real=True)
    norm = Matrix([sqrt(x*x + y*y)])
  \end{minted}
  \caption{The two-norm function over $\RR^2$ with Sympy}
\end{listing}


The smooth jacobian

\begin{listing}[H] 
  \begin{minted}[frame=single]{python}
    v = Matrix([x, y])
    J_ = f.jacobian(v)
  \end{minted}
  \caption{the smooth jacobian}
\end{listing}

In zero
\begin{listing}[H] 
  \begin{minted}[frame=single]{python}
    from sympy import limit
    def lim0(expr):
        return limit(expr.subs(x,t).subs(y,t), t, 0)
  \end{minted}
  \caption{a limit}
\end{listing}

\begin{listing}[H] 
  \begin{minted}[frame=single]{python}
    from sympy import Piecewise
    J = Matrix(J_.shape[0], J_.shape[1], 
           lambda i, j: Piecewise(
               (J_[i, j], v.norm() > 0.),
               (lim0(J_[i, j]), v.norm() <= 0.)))
  \end{minted}
  \caption{a limit}
\end{listing}


\begin{equation}
  \begin{array}{ll}
    \left [
      \begin{array}{c}
        x\\
        y
      \end{array} \right]
    \mapsto \left\{
        \begin{array}{ll}
          \left[
            \begin{array}{c}
            \frac{x}{\sqrt{x^2+y^2}}\\
            \frac{y}{\sqrt{x^2+y^2}}
          \end{array} \right] & \mbox{if } (x, y) \in \RR^{\star 2} \\
        \left[
          \begin{array}{c}
            \frac{\sqrt{2}}{2}\\
            \frac{\sqrt{2}}{2}
          \end{array} \right] & \mbox{if } (x, y) = (0, 0)
        
      \end{array}
    \right.
  \end{array}
\end{equation}


\begin{listing}[H] 
  \begin{minted}[frame=single]{c}
void norm2d_jacobian(
    double x,
    double y,
    double *result)
{
    double x1 = 0.;
    int x4 = 0;
    double x2 = 0.;
    double x3 = 0.;
    x1 = sqrt(x*x + y*y);
    x4 = x1 > 0.;
    int x5 = 0;
    x5 = x1 <= 0.;
    if (x4)
    {
        x2 = 1.0/x1;
        x3 = 1.0*x2;
    }
    if (x4)
    {
        result[0] = x*x3;
    }
    else if (x5)
    {
        result[0] = 0.707106781186547524400844362104849039284835937688474;
    }
    if (x4)
    {
        result[1] = x3*y;
    }
    else if (x5)
    {
        result[1] = 0.707106781186547524400844362104849039284835937688474;
    }
}
\end{minted}
\caption{a limit}
\end{listing}

\subsubsection{this function may overflow}

\subsubsection{a corrected jacobian}

\section{Jacobians}

The Heaviside function is noted $\theta$

The $\epsilon$ parameter is important to avoid infinites or not a number values. 
The verification is performed by the value analysis.

\subsection{The Alart Curnier and the Jean Moreau functions}

Given the following notations:

\begin{equation}
  \begin{array}{c}
    \Delta_n = r_n -\rho_n  u_n\\
    \Delta_{t1} = t_{t1} - \rho_{t1}  u_{t1}\\
    \Delta_{t2} = t_{t2} - \rho_{t2}  u_{t2}\\
    \Delta_{t} = \left [
      \begin{array}{c}
        \Delta_{t1}\\
        \Delta_{t2}
      \end{array} \right]
  \end{array}
\end{equation}

\subsubsection{Alart Curnier}

The Alart Curnier function $F_{AC}$ is written as:

\begin{equation}
  F_{AC} = \input{fac.tex}
\end{equation}

We have 
\begin{equation}
  A = \left[ A_0 A_1 A_2 \right]
\end{equation}

with:
\begin{equation}
  A_0 = \input{fac_A0.tex}
\end{equation}

\begin{equation}
  A_1 = \input{fac_A1.tex}
\end{equation}

\begin{equation}
  A_2 = \input{fac_A2.tex}
\end{equation}

and

\begin{equation}
  B = \left[ B_0 B_1 B_2 \right]
\end{equation}

with:
\begin{equation}
  B_0 = \input{fac_B0.tex}
\end{equation}

\begin{equation}
  B_1 = \input{fac_B1.tex}
\end{equation}

\begin{equation}
  B_2 = \input{fac_B2.tex}
\end{equation}

\subsubsection{Jean Moreau}
The Jean Moreau function $F_{JM}$ is written as:

\begin{equation}
  F_{JM} = \input{fJM.tex}
\end{equation}

We have 
\begin{equation}
  A = \left[ A_0 A_1 A_2 \right]
\end{equation}

with:
\begin{equation}
  A_0 = \input{fJM_A0.tex}
\end{equation}

\begin{equation}
  A_1 = \input{fJM_A1.tex}
\end{equation}

\begin{equation}
  A_2 = \input{fJM_A2.tex}
\end{equation}

and

\begin{equation}
  B = \left[ B_0 B_1 B_2 \right]
\end{equation}

with:
\begin{equation}
  B_0 = \input{fJM_B0.tex}
\end{equation}

\begin{equation}
  B_1 = \input{fJM_B1.tex}
\end{equation}

\begin{equation}
  B_2 = \input{fJM_B2.tex}
\end{equation}

\subsection{The normal map function}

With the notations:
\begin{equation}
  \begin{array}{c}
    \Delta_{t1} = \mu u_{t1}-r_{t1}\\
    \Delta_{t2} = \mu u_{t2}-r_{t2}\\
    \Delta_{t} = \left [
      \begin{array}{c}
        \Delta_{t1}\\
        \Delta_{t2}
      \end{array} \right]
  \end{array}
\end{equation}

\begin{equation}
  F_{nat} = \input{fnat.tex}
\end{equation}

\begin{equation}
  A_0 = \input{A0_fnat.tex}
\end{equation}

\begin{equation}
  A_{01} = \input{A01_fnat.tex}
\end{equation}

\begin{equation}
  A_{02} = \input{A02_fnat.tex}
\end{equation}

\begin{equation}
  A_{11} = \input{A11_fnat.tex}
\end{equation}

\begin{equation}
  A_{12} = \input{A12_fnat.tex}
\end{equation}

\begin{equation}
  A_{21} = \input{A21_fnat.tex}
\end{equation}

\begin{equation}
  A_{22} = \input{A22_fnat.tex}
\end{equation}

\begin{equation}
  B_0 = \input{B0_fnat.tex}
\end{equation}

\begin{equation}
  B_{01} = \input{B01_fnat.tex}
\end{equation}

\begin{equation}
  B_{02} = \input{B02_fnat.tex}
\end{equation}

\begin{equation}
  B_{11} = \input{B11_fnat.tex}
\end{equation}

\begin{equation}
  B_{12} = \input{B12_fnat.tex}
\end{equation}

\begin{equation}
  B_{21} = \input{B21_fnat.tex}
\end{equation}

\begin{equation}
  B_{22} = \input{B22_fnat.tex}
\end{equation}

\subsection{The Fischer Burmeister function}

\section{Conclusion}

Symbolic differentiation -> inefficient code

A better approach Symbolic code generation for the function, Automatic
differentiation of the smooth part + user provided values on nonsmooth part.



\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
\endinput

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: default-shell-escape 
%%% End: 
